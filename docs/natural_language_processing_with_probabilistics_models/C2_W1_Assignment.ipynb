{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# Assignment 1: Autocorrect\n",
    "\n",
    "Welcome to the first assignment of Course 2. This assignment will give you a chance to brush up on your python and probability skills. In doing so, you will implement an auto-correct system that is very effective and useful.\n",
    "\n",
    "## Important Note on Submission to the AutoGrader\n",
    "\n",
    "Before submitting your assignment to the AutoGrader, please make sure you are not doing the following:\n",
    "\n",
    "1. You have not added any _extra_ `print` statement(s) in the assignment.\n",
    "2. You have not added any _extra_ code cell(s) in the assignment.\n",
    "3. You have not changed any of the function parameters.\n",
    "4. You are not using any global variables inside your graded exercises. Unless specifically instructed to do so, please refrain from it and use the local variables instead.\n",
    "5. You are not changing the assignment code where it is not required, like creating _extra_ variables.\n",
    "\n",
    "If you do any of the following, you will get something like, `Grader Error: Grader feedback not found` (or similarly unexpected) error upon submitting your assignment. Before asking for help/debugging the errors in your assignment, check for these first. If this is the case, and you don't remember the changes you have made, you can get a fresh copy of the assignment by following these [instructions](https://www.coursera.org/learn/probabilistic-models-in-nlp/supplement/saGQf/how-to-refresh-your-workspace)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [0 - Overview](#0)\n",
    "    - [0.1 - Edit Distance](#0-1)\n",
    "- [1 - Data Preprocessing](#1)\n",
    "    - [Exercise 1 - process_data (UNQ_C1)](#ex-1)\n",
    "    - [Exercise 2 - get_count (UNQ_C2)](#ex-2)\n",
    "    - [Exercise 3 - get_probs (UNQ_C3)](#ex-3)\n",
    "- [2 - String Manipulations](#2)\n",
    "    - [Exercise 4 - delete_letter (UNQ_C4)](#ex-4)\n",
    "    - [Exercise 5 - switch_letter (UNQ_C5)](#ex-5)\n",
    "    - [Exercise 6 - replace_letter (UNQ_C6)](#ex-6)\n",
    "    - [Exercise 7 - insert_letter (UNQ_C7)](#ex-7)\n",
    "- [3 - Combining the Edits](#3)\n",
    "    - [3.1 - Edit One Letter](#3-1)\n",
    "        - [Exercise 8 - edit_one_letter (UNQ_C8)](#ex-8)\n",
    "    - [3.2 - Edit Two Letters](#3-2)\n",
    "        - [Exercise 9 - edit_two_letters (UNQ_C9)](#ex-9)\n",
    "    - [3.3 - Suggest Spelling Suggestions](#3-3)\n",
    "        - [Exercise 10 - get_corrections (UNQ_C20)](#ex-10)\n",
    "- [4 - Minimum Edit Distance](#4)\n",
    "    - [4.1 - Dynamic Programming](#4-1)\n",
    "        - [Exercise 11 - min_edit_distance (UNQ_C11)](#ex-11)\n",
    "- [5 - Backtrace (Optional)](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "## 0 - Overview\n",
    "\n",
    "You use autocorrect every day on your cell phone and computer. In this assignment, you will explore what really goes on behind the scenes. Of course, the model you are about to implement is not identical to the one used in your phone, but it is still quite good. \n",
    "\n",
    "By completing this assignment you will learn how to: \n",
    "\n",
    "- Get a word count given a corpus\n",
    "- Get a word probability in the corpus \n",
    "- Manipulate strings \n",
    "- Filter strings \n",
    "- Implement Minimum edit distance to compare strings and to help find the optimal path for the edits. \n",
    "- Understand how dynamic programming works\n",
    "\n",
    "\n",
    "Similar systems are used everywhere. \n",
    "- For example, if you type in the word **\"I am lerningg\"**, chances are very high that you meant to write **\"learning\"**, as shown in **Figure 1**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/auto-correct.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:300px;height:250px;\" /> Figure 1 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "source": [
    "<a name='0-1'></a>\n",
    "### 0.1 - Edit Distance\n",
    "\n",
    "In this assignment, you will implement models that correct words that are 1 and 2 edit distances away. \n",
    "- We say two words are n edit distance away from each other when we need n edits to change one word into another. \n",
    "\n",
    "An edit could consist of one of the following options: \n",
    "\n",
    "- Delete (remove a letter): ‘hat’ => ‘at, ha, ht’\n",
    "- Switch (swap 2 adjacent letters): ‘eta’ => ‘eat, tea,...’\n",
    "- Replace (change 1 letter to another): ‘jat’ => ‘hat, rat, cat, mat, ...’\n",
    "- Insert (add a letter): ‘te’ => ‘the, ten, ate, ...’\n",
    "\n",
    "You will be using the four methods above to implement an Auto-correct. \n",
    "- To do so, you will need to compute probabilities that a certain word is correct given an input. \n",
    "\n",
    "This auto-correct you are about to implement was first created by [Peter Norvig](https://en.wikipedia.org/wiki/Peter_Norvig) in 2007. \n",
    "- His [original article](https://norvig.com/spell-correct.html) may be a useful reference for this assignment.\n",
    "\n",
    "The goal of our spell check model is to compute the following probability:\n",
    "\n",
    "$$P(c|w) = \\frac{P(w|c)\\times P(c)}{P(w)} \\tag{Eqn-1}$$\n",
    "\n",
    "The equation above is [Bayes Rule](https://en.wikipedia.org/wiki/Bayes%27_theorem). \n",
    "- Equation 1 says that the probability of a word being correct $P(c|w) $is equal to the probability of having a certain word $w$, given that it is correct $P(w|c)$, multiplied by the probability of being correct in general $P(C)$ divided by the probability of that word $w$ appearing $P(w)$ in general.\n",
    "- To compute equation 1, you will first import a data set and then create all the probabilities that you need using that data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import w1_unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": [
    "As in any other machine learning task, the first thing you have to do is process your data set. \n",
    "- Many courses load in pre-processed data for you. \n",
    "- However, in the real world, when you build these NLP systems, you load the datasets and process them.\n",
    "- So let's get some real world practice in pre-processing the data!\n",
    "\n",
    "Your first task is to read in a file called **'shakespeare.txt'** which is found in your file directory. To look at this file you can go to `File ==> Open `. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "source": [
    "<a name='ex-1'></a>\n",
    "### Exercise 1 - process_data\n",
    "Implement the function `process_data` which \n",
    "\n",
    "1) Reads in a corpus (text file)\n",
    "\n",
    "2) Changes everything to lowercase\n",
    "\n",
    "3) Returns a list of words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "source": [
    "#### Options and Hints\n",
    "- If you would like more of a real-life practice, don't open the 'Hints' below (yet) and try searching the web to derive your answer.\n",
    "- If you want a little help, click on the green \"General Hints\" section by clicking on it with your mouse.\n",
    "- If you get stuck or are not getting the expected results, click on the green 'Detailed Hints' section to get hints for each step that you'll take to complete this function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>General Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    \n",
    "General Hints to get started\n",
    "<ul>\n",
    "    <li>Python <a href=\"https://docs.python.org/3/tutorial/inputoutput.html\">input and output<a></li>\n",
    "    <li>Python <a href=\"https://docs.python.org/3/library/re.html\" >'re' documentation </a> </li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Detailed Hints</b></font>\n",
    "</summary>\n",
    "<p>     \n",
    "Detailed hints if you're stuck\n",
    "<ul>\n",
    "    <li>Use 'with' syntax to read a file</li>\n",
    "    <li>Decide whether to use 'read()' or 'readline().  What's the difference?</li>\n",
    "    <li>You can use str.lower() to convert to lowercase.</li>\n",
    "    <li>Use re.findall(pattern, string)</li>\n",
    "    <li>Look for the \"Raw String Notation\" section in the Python 're' documentation to understand the difference between r'\\W', r'\\W' and '\\\\W'. </li>\n",
    "    <li>For the pattern, decide between using '\\s', '\\w', '\\s+' or '\\w+'.  What do you think are the differences?</li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1 GRADED FUNCTION: process_data\n",
    "def process_data(file_name):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        A file_name which is found in your current directory. You just have to read it in.\n",
    "    Output:\n",
    "        words: a list containing all the words in the corpus (text file you read) in lower case.\n",
    "    \"\"\"\n",
    "    words = []  # return this variable correctly\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Open the file, read its contents into a string variable\n",
    "    with open(file_name, \"r\") as fh:\n",
    "        words_data = fh.read()\n",
    "    # convert all letters to lower case\n",
    "    words = words_data.lower()\n",
    "    # Convert every word to lower case and return them in a list.\n",
    "    words = re.findall(r\"\\w+\", words)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {},
   "source": [
    "Note, in the following cell, 'words' is converted to a python `set`. This eliminates any duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43b363d81ae4b689946ece5c682cd59",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten words in the text are: \n",
      "['o', 'for', 'a', 'muse', 'of', 'fire', 'that', 'would', 'ascend', 'the']\n",
      "There are 6116 unique words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "word_l = process_data(\"./data/shakespeare.txt\")\n",
    "vocab = set(word_l)  # this will be your new vocabulary\n",
    "print(f\"The first ten words in the text are: \\n{word_l[0:10]}\")\n",
    "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65eabff63a45729fe45fb5ade58bdc",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "```Python\n",
    "The first ten words in the text are: \n",
    "['o', 'for', 'a', 'muse', 'of', 'fire', 'that', 'would', 'ascend', 'the']\n",
    "There are 6116 unique words in the vocabulary.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3933fab20d04ec698c2621248eb3be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "w1_unittest.test_process_data(process_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4641cc4064e0191573fe9c69df29b",
   "metadata": {},
   "source": [
    "<a name='ex-2'></a>\n",
    "### Exercise 2 - get_count\n",
    "\n",
    "Implement a `get_count` function that returns a dictionary\n",
    "- The dictionary's keys are words\n",
    "- The value for each word is the number of times that word appears in the corpus. \n",
    "\n",
    "For example, given the following sentence: **\"I am happy because I am learning\"**, your dictionary should return the following: \n",
    "<table style=\"width:20%\">\n",
    "\n",
    "  <tr>\n",
    "    <td> <b>Key </b>  </td>\n",
    "    <td> <b>Value </b> </td> \n",
    "\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> I  </td>\n",
    "    <td> 2</td> \n",
    " \n",
    "  </tr>\n",
    "   \n",
    "  <tr>\n",
    "    <td>am</td>\n",
    "    <td>2</td> \n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td>happy</td>\n",
    "    <td>1</td> \n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>because</td>\n",
    "    <td>1</td> \n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>learning</td>\n",
    "    <td>1</td> \n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "**Instructions**: \n",
    "Implement a `get_count` which returns a dictionary where the key is a word and the value is the number of times the word appears in the list.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8309879909854d7188b41380fd92a7c3",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>Try implementing this using a for loop and a regular dictionary. This may be good practice for similar coding interview questions</li>\n",
    "    <li>You can also use defaultdict instead of a regular dictionary, along with the for loop</li>\n",
    "    <li>Otherwise, to skip using a `for` loop, you can use Python's <a href=\"https://docs.python.org/3.7/library/collections.html#collections.Counter\" > Counter class</a> </li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed186c9a28b402fb0bc4494df01f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
    "# UNQ_C2 GRADED FUNCTION: get_count\n",
    "def get_count(word_l):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word_l: a set of words representing the corpus.\n",
    "    Output:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    \"\"\"\n",
    "    word_count_dict = {}  # fill this with word counts\n",
    "    ### START CODE HERE\n",
    "    for word in word_l:\n",
    "        if word in word_count_dict:\n",
    "            word_count_dict[word] += 1\n",
    "        else:\n",
    "            word_count_dict[word] = 1\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb1e1581032b452c9409d6c6813c49d1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6116 key values pairs\n",
      "The count for the word 'thee' is 240\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "word_count_dict = get_count(word_l)\n",
    "print(f\"There are {len(word_count_dict)} key values pairs\")\n",
    "print(f\"The count for the word 'thee' is {word_count_dict.get('thee',0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cbbc1e968416e875cc15c1202d7eb",
   "metadata": {},
   "source": [
    "\n",
    "#### Expected Output\n",
    "```Python\n",
    "There are 6116 key values pairs\n",
    "The count for the word 'thee' is 240\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "277c27b1587741f2af2001be3712ef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "w1_unittest.test_get_count(get_count, word_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7b79bc585a40fcaf58bf750017e135",
   "metadata": {},
   "source": [
    "<a name='ex-3'></a>\n",
    "### Exercise 3 - get_probs\n",
    "Given the dictionary of word counts, compute the probability that each word will appear if randomly selected from the corpus of words.\n",
    "\n",
    "$$P(w_i) = \\frac{C(w_i)}{M} \\tag{Eqn-2}$$\n",
    "where \n",
    "\n",
    "$C(w_i)$ is the total number of times $w_i$ appears in the corpus.\n",
    "\n",
    "$M$ is the total number of words in the corpus.\n",
    "\n",
    "For example, the probability of the word 'am' in the sentence **'I am happy because I am learning'** is:\n",
    "\n",
    "$$P(am) = \\frac{C(w_i)}{M} = \\frac {2}{7} \\tag{Eqn-3}.$$\n",
    "\n",
    "**Instructions:** Implement `get_probs` function which gives you the probability \n",
    "that a word occurs in a sample. This returns a dictionary where the keys are words, and the value for each word is its probability in the corpus of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916684f9a58a4a2aa5f864670399430d",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "General advice\n",
    "<ul>\n",
    "    <li> Use dictionary.values() </li>\n",
    "    <li> Use sum() </li>\n",
    "    <li> The cardinality (number of words in the corpus should be equal to len(word_l).  You will calculate this same number, but using the word count dictionary.</li>\n",
    "</ul>\n",
    "    \n",
    "If you're using a for loop:\n",
    "<ul>\n",
    "    <li> Use dictionary.keys() </li>\n",
    "</ul>\n",
    "    \n",
    "If you're using a dictionary comprehension:\n",
    "<ul>\n",
    "    <li>Use dictionary.items() </li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1671c31a24314836a5b85d7ef7fbf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3 GRADED FUNCTION: get_probs\n",
    "def get_probs(word_count_dict):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    Output:\n",
    "        probs: A dictionary where keys are the words and the values are the probability that a word will occur.\n",
    "    \"\"\"\n",
    "    probs = {}  # return this variable correctly\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    M = sum(word_count_dict.values())\n",
    "\n",
    "    # get the total count of words for all words in the dictionary\n",
    "    for key in word_count_dict.keys():\n",
    "        probs[key] = word_count_dict.get(key, 0) / M\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33b0902fd34d4ace834912fa1002cf8e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of probs is 6116\n",
      "P('thee') is 0.0045\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "probs = get_probs(word_count_dict)\n",
    "print(f\"Length of probs is {len(probs)}\")\n",
    "print(f\"P('thee') is {probs['thee']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa52606d8c4a75a9b52967216f8f3f",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "\n",
    "```Python\n",
    "Length of probs is 6116\n",
    "P('thee') is 0.0045\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5a1fa73e5044315a093ec459c9be902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "w1_unittest.test_get_probs(get_probs, word_count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf66aed5cc84ca1b48e60bad68798a8",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - String Manipulations\n",
    "\n",
    "Now that you have computed $P(w_i)$ for all the words in the corpus, you will write a few functions to manipulate strings so that you can edit the erroneous strings and return the right spellings of the words. In this section, you will implement four functions: \n",
    "\n",
    "* `delete_letter`: given a word, it returns all the possible strings that have **one character removed**. \n",
    "* `switch_letter`: given a word, it returns all the possible strings that have **two adjacent letters switched**.\n",
    "* `replace_letter`: given a word, it returns all the possible strings that have **one character replaced by another different letter**.\n",
    "* `insert_letter`: given a word, it returns all the possible strings that have an **additional character inserted**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d3efd5258a48a79c179ea5c6759f01",
   "metadata": {},
   "source": [
    "#### List comprehensions\n",
    "\n",
    "String and list manipulation in python will often make use of a python feature called  [list comprehensions](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions). The routines below will be described as using list comprehensions, but if you would rather implement them in another way, you are free to do so as long as the result is the same. Further, the following section will provide detailed instructions on how to use list comprehensions and how to implement the desired functions. If you are a python expert, feel free to skip the python hints and move to implementing the routines directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9bc0b9dd2c44919cc8dcca39b469f8",
   "metadata": {},
   "source": [
    "Python List Comprehensions embed a looping structure inside of a list declaration, collapsing many lines of code into a single line. If you are not familiar with them, they seem slightly out of order relative to for loops. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e382214b5f147d187d36a2058b9c724",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/GenericListComp3.PNG' alt=\"alternate text\" width=\"width\" height=\"height\"  style=\"width:800px;height:400px;\"/> Figure 2 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b09d5ef5b5e4bb6ab9b829b10b6a29f",
   "metadata": {},
   "source": [
    "The diagram above shows that the components of a list comprehension are the same components you would find in a typical for loop that appends to a list, but in a different order. With that in mind, we'll continue the specifics of this assignment. We will be very descriptive for the first function, `deletes()`, and less so in later functions as you become familiar with list comprehensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50416e276a0479cbe66534ed1713a40",
   "metadata": {},
   "source": [
    "<a name='ex-4'></a>\n",
    "### Exercise 4 - delete_letter\n",
    "\n",
    "**Instructions for delete_letter():** Implement a `delete_letter()` function that, given a word, returns a list of strings with one character deleted. \n",
    "\n",
    "For example, given the word **nice**, it would return the set: {'ice', 'nce', 'nic', 'nie'}. \n",
    "\n",
    "**Step 1:** Create a list of 'splits'. This is all the ways you can split a word into Left and Right: For example,   \n",
    "'nice is split into : `[('', 'nice'), ('n', 'ice'), ('ni', 'ce'), ('nic', 'e'), ('nice', '')]`\n",
    "This is common to all four functions (delete, replace, switch, insert).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a27a456b804aa2a380d5edf15a5daf",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/Splits1.PNG' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:650px;height:200px;\" /> Figure 3 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1944c39560714e6e80c856f20744a8e5",
   "metadata": {},
   "source": [
    "**Step 2:** This is specific to `delete_letter`. Here, we are generating all words that result from deleting one character.  \n",
    "This can be done in a single line with a list comprehension. You can make use of this type of syntax:  \n",
    "`[f(a,b) for a, b in splits if condition]`  \n",
    "\n",
    "For our 'nice' example you get: \n",
    "['ice', 'nce', 'nie', 'nic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ca27006b894b04b6fc8b79396e2797",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/ListComp2.PNG' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:550px;height:300px;\" /> Figure 4 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61877af4e7f4313ad8234302950b331",
   "metadata": {},
   "source": [
    "#### Levels of assistance\n",
    "\n",
    "Try this exercise with these levels of assistance.  \n",
    "- We hope that this will make it both a meaningful experience but also not a frustrating experience. \n",
    "- Start with level 1, then move onto level 2, and 3 as needed.\n",
    "\n",
    "    - Level 1. Try to think this through and implement this yourself.\n",
    "    - Level 2. Click on the \"Level 2 Hints\" section for some hints to get started.\n",
    "    - Level 3. If you would prefer more guidance, please click on the \"Level 3 Hints\" cell for step by step instructions.\n",
    "    \n",
    "- If you are still stuck, look at the images in the \"list comprehensions\" section above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d5ab97d17b4c38ab41a2b065bbd0c0",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Level 2 Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li><a href=\"\" > Use array slicing like my_string[0:2] </a> </li>\n",
    "    <li><a href=\"\" > Use list comprehensions or for loops </a> </li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ffc1ce1c7b4df9ace1bc936b8b1dc2",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Level 3 Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>splits: Use array slicing, like my_str[0:2], to separate a string into two pieces.</li>\n",
    "    <li>Do this in a loop or list comprehension, so that you have a list of tuples.\n",
    "    <li> For example, \"cake\" can get split into \"ca\" and \"ke\". They're stored in a tuple (\"ca\",\"ke\"), and the tuple is appended to a list.  We'll refer to these as L and R, so the tuple is (L,R)</li>\n",
    "    <li>When choosing the range for your loop, if you input the word \"cans\" and generate the tuple  ('cans',''), make sure to include an if statement to check the length of that right-side string (R) in the tuple (L,R) </li>\n",
    "    <li>deletes: Go through the list of tuples and combine the two strings together. You can use the + operator to combine two strings</li>\n",
    "    <li>When combining the tuples, make sure that you leave out a middle character.</li>\n",
    "    <li>Use array slicing to leave out the first character of the right substring.</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76127f4a2f6a44fba749ea7800e59d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
    "# UNQ_C4 GRADED FUNCTION: deletes\n",
    "def delete_letter(word, verbose=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the string/word for which you will generate all possible words\n",
    "                in the vocabulary which have 1 missing character\n",
    "    Output:\n",
    "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
    "    \"\"\"\n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    for i in range(len(word)):\n",
    "        split_l.append(([word[:i], word[i:]]))\n",
    "\n",
    "    # deletes with a list comprehension\n",
    "    delete_l = [L + R[1:] for L, R in split_l if R]\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
    "\n",
    "    return delete_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "903197826d2e44dfa0208e8f97c69327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word cans, \n",
      "split_l = [['', 'cans'], ['c', 'ans'], ['ca', 'ns'], ['can', 's']], \n",
      "delete_l = ['ans', 'cns', 'cas', 'can']\n"
     ]
    }
   ],
   "source": [
    "delete_word_l = delete_letter(word=\"cans\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015066fb96f841e5be1e03a9eaadc3b6",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "```CPP\n",
    "Note: You might get a slightly different result with split_l\n",
    "\n",
    "input word cans, \n",
    "split_l = [('', 'cans'), ('c', 'ans'), ('ca', 'ns'), ('can', 's')], \n",
    "delete_l = ['ans', 'cns', 'cas', 'can']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff116bae5b45f6b6dae177083008cf",
   "metadata": {},
   "source": [
    "#### Note 1\n",
    "- Notice how it has the extra tuple `('cans', '')`.\n",
    "- This will be fine as long as you have checked the size of the right-side substring in tuple (L,R).\n",
    "- Can you explain why this will give you the same result for the list of deletion strings (delete_l)?\n",
    "\n",
    "```CPP\n",
    "input word cans, \n",
    "split_l = [('', 'cans'), ('c', 'ans'), ('ca', 'ns'), ('can', 's'), ('cans', '')], \n",
    "delete_l = ['ans', 'cns', 'cas', 'can']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9075f00cfa8d463f84130041b1e44ca7",
   "metadata": {},
   "source": [
    "#### Note 2\n",
    "If you end up getting the same word as your input word, like this:\n",
    "\n",
    "```Python\n",
    "input word cans, \n",
    "split_l = [('', 'cans'), ('c', 'ans'), ('ca', 'ns'), ('can', 's'), ('cans', '')], \n",
    "delete_l = ['ans', 'cns', 'cas', 'can', 'cans']\n",
    "```\n",
    "\n",
    "- Check how you set the `range`.\n",
    "- See if you check the length of the string on the right-side of the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15abde8c5d2e435093904b13db685a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs of delete_letter('at') is 2\n"
     ]
    }
   ],
   "source": [
    "# test # 2\n",
    "print(f\"Number of outputs of delete_letter('at') is {len(delete_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e20a2a0e21149b5b06860e930401eb5",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "\n",
    "```CPP\n",
    "Number of outputs of delete_letter('at') is 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72c31777baf4441b988909d29205560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "w1_unittest.test_delete_letter(delete_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5734001bcbac423990a4356310d8df13",
   "metadata": {},
   "source": [
    "<a name='ex-5'></a>\n",
    "### Exercise 5 - switch_letter\n",
    "\n",
    "**Instructions for switch_letter()**: Now implement a function that switches two letters in a word. It takes in a word and returns a list of all the possible switches of two letters **that are adjacent to each other**. \n",
    "- For example, given the word 'eta', it returns {'eat', 'tea'}, but does not return 'ate'.\n",
    "\n",
    "**Step 1:** is the same as in delete_letter()  \n",
    "**Step 2:** A list comprehension or for loop which forms strings by swapping adjacent letters. This is of the form:  \n",
    "`[f(L,R) for L, R in splits if condition]`  where 'condition' will test the length of R in a given iteration. See below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27531e93873647d9a5bf1112f2051a59",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/Switches1.PNG' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:600px;height:200px;\"/> Figure 5 </div>      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3041e9ffdb2416ea2009d3a6a4c5716",
   "metadata": {},
   "source": [
    "#### Levels of difficulty\n",
    "\n",
    "Try this exercise with these levels of difficulty.  \n",
    "- Level 1. Try to think this through and implement this yourself.\n",
    "- Level 2. Click on the \"Level 2 Hints\" section for some hints to get started.\n",
    "- Level 3. If you would prefer more guidance, please click on the \"Level 3 Hints\" cell for step by step instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ae71b6e24e4355a139fb9fe2e09b64",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Level 2 Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li><a href=\"\" > Use array slicing like my_string[0:2] </a> </li>\n",
    "    <li><a href=\"\" > Use list comprehensions or for loops </a> </li>\n",
    "    <li>To do a switch, think of the whole word as divided into 4 distinct parts.  Write out 'cupcakes' on a piece of paper and see how you can split it into ('cupc', 'k', 'a', 'es')</li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141936c6c8a4c478a75aea4ff665469",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Level 3 Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>splits: Use array slicing, like my_str[0:2], to separate a string into two pieces.</li>\n",
    "    <li>Splitting is the same as for delete_letter</li>\n",
    "    <li>To perform the switch, go through the list of tuples and combine four strings together. You can use the + operator to combine strings</li>\n",
    "    <li>The four strings will be the left substring from the split tuple, followed by the first (index 1) character of the right substring, then the zero-th character (index 0) of the right substring, and then the remaining part of the right substring.</li>\n",
    "    <li>Unlike delete_letter, you will want to check that your right substring is at least a minimum length.  To see why, review the previous hint bullet point (directly before this one).</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd7c096f4dcf400fbdceb075ef31fca3",
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
    "# UNQ_C5 GRADED FUNCTION: switches\n",
    "def switch_letter(word, verbose=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: input string\n",
    "     Output:\n",
    "        switches: a list of all possible strings with one adjacent charater switched\n",
    "    \"\"\"\n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    for i in range(len(word)):\n",
    "        split_l.append(([word[:i], word[i:]]))\n",
    "\n",
    "    switch_l = [a + b[1] + b[0] + b[2:] for a, b in split_l if len(b) > 1]\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\")\n",
    "\n",
    "    return switch_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b427a666a1b549ef9b573d6f946bfc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = eta \n",
      "split_l = [['', 'eta'], ['e', 'ta'], ['et', 'a']] \n",
      "switch_l = ['tea', 'eat']\n"
     ]
    }
   ],
   "source": [
    "switch_word_l = switch_letter(word=\"eta\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310869696a145bf841235dd6c036af8",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "\n",
    "```Python\n",
    "Input word = eta \n",
    "split_l = [('', 'eta'), ('e', 'ta'), ('et', 'a')] \n",
    "switch_l = ['tea', 'eat']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f166d9f0ce4939b04b8e9245f75c27",
   "metadata": {},
   "source": [
    "#### Note 1\n",
    "\n",
    "You may get this:\n",
    "```Python\n",
    "Input word = eta \n",
    "split_l = [('', 'eta'), ('e', 'ta'), ('et', 'a'), ('eta', '')] \n",
    "switch_l = ['tea', 'eat']\n",
    "```\n",
    "- Notice how it has the extra tuple `('eta', '')`.\n",
    "- This is also correct.\n",
    "- Can you think of why this is the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10029e1707434ab3fe295caea7d13f",
   "metadata": {},
   "source": [
    "#### Note 2\n",
    "\n",
    "If you get an error\n",
    "```Python\n",
    "IndexError: string index out of range\n",
    "```\n",
    "- Please see if you have checked the length of the strings when switching characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f68f0888c55a4478ace3eac39384dff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs of switch_letter('at') is 1\n"
     ]
    }
   ],
   "source": [
    "# test # 2\n",
    "print(f\"Number of outputs of switch_letter('at') is {len(switch_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94f5a17fa734d288763e7d9a3758173",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "\n",
    "```CPP\n",
    "Number of outputs of switch_letter('at') is 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "421b839107204e409e0496d3d944026c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "w1_unittest.test_switch_letter(switch_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981b37c798e44f684168605b9db02c6",
   "metadata": {},
   "source": [
    "<a name='ex-6'></a>\n",
    "### Exercise 6 - replace_letter\n",
    "**Instructions for replace_letter()**: Now implement a function that takes in a word and returns a list of strings with one **replaced letter** from the original word. \n",
    "\n",
    "**Step 1:** is the same as in `delete_letter()`\n",
    "\n",
    "**Step 2:** A list comprehension or for loop which form strings by replacing letters.  This can be of the form:  \n",
    "`[f(a,b,c) for a, b in splits if condition for c in string]`   Note the use of the second for loop.  \n",
    "It is expected in this routine that one or more of the replacements will include the original word. For example, replacing the first letter of 'ear' with 'e' will return 'ear'.\n",
    "\n",
    "**Step 3:** Remove the original input letter from the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1800d1c114147a536b8aa907907c7",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>To remove a word from a list, first store its contents inside a set()</li>\n",
    "    <li>Use set.discard('the_word') to remove a word in a set.  Using set.remove('the_word') throws a KeyError if the word does not exist in the set. </li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9082857fd66e4025bba99b1a80c5d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
    "# UNQ_C6 GRADED FUNCTION: replaces\n",
    "def replace_letter(word, verbose=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the input string/word\n",
    "    Output:\n",
    "        replaces: a list of all possible strings where we replaced one letter from the original word.\n",
    "    \"\"\"\n",
    "    letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    for i in range(len(word)):\n",
    "        split_l.append(([word[:i], word[i:]]))\n",
    "\n",
    "    replace_set = [L + c + R[1:] for L, R in split_l if R for c in letters]\n",
    "    replace_set = set(replace_set)\n",
    "    replace_set.remove(word)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # turn the set back into a list and sort it, for easier viewing\n",
    "    replace_l = sorted(list(replace_set))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")\n",
    "\n",
    "    return replace_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71b4158a9f3d49279f06ec9197b84529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = can \n",
      "split_l = [['', 'can'], ['c', 'an'], ['ca', 'n']] \n",
      "replace_l ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n"
     ]
    }
   ],
   "source": [
    "replace_l = replace_letter(word=\"can\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6038e703eb6b4df2ba5a71336b77ea4e",
   "metadata": {},
   "source": [
    "#### Expected Output**: \n",
    "```Python\n",
    "Input word = can \n",
    "split_l = [('', 'can'), ('c', 'an'), ('ca', 'n')] \n",
    "replace_l ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n",
    "```\n",
    "- Note how the input word 'can' should not be one of the output words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ca0f16c5be4617b5535c40faa36c79",
   "metadata": {},
   "source": [
    "#### Note 1\n",
    "If you get something like this:\n",
    "\n",
    "```Python\n",
    "Input word = can \n",
    "split_l = [('', 'can'), ('c', 'an'), ('ca', 'n'), ('can', '')] \n",
    "replace_l ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n",
    "```\n",
    "- Notice how split_l has an extra tuple `('can', '')`, but the output is still the same, so this is okay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa693c20bd460494e518b8cb84ef11",
   "metadata": {},
   "source": [
    "#### Note 2\n",
    "If you get something like this:\n",
    "```Python\n",
    "Input word = can \n",
    "split_l = [('', 'can'), ('c', 'an'), ('ca', 'n'), ('can', '')] \n",
    "replace_l ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cana', 'canb', 'canc', 'cand', 'cane', 'canf', 'cang', 'canh', 'cani', 'canj', 'cank', 'canl', 'canm', 'cann', 'cano', 'canp', 'canq', 'canr', 'cans', 'cant', 'canu', 'canv', 'canw', 'canx', 'cany', 'canz', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n",
    "```\n",
    "- Notice how there are strings that are 1 letter longer than the original word, such as `cana`.\n",
    "- Please check for the case when there is an empty string `''`, and if so, do not use that empty string when setting replace_l."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8acbee542ae4f9e87d350f4747cb88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs of replace_letter('at') is 50\n"
     ]
    }
   ],
   "source": [
    "# test # 2\n",
    "print(f\"Number of outputs of replace_letter('at') is {len(replace_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a51dd6baab431990c6adcc83aa7fba",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "```CPP\n",
    "Number of outputs of replace_letter('at') is 50\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d84866adce69467fa81441dc6c47fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "w1_unittest.test_replace_letter(replace_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb6c23654f54f5b91a38c31054c5587",
   "metadata": {},
   "source": [
    "<a name='ex-7'></a>\n",
    "### Exercise 7 - insert_letter\n",
    "\n",
    "**Instructions for insert_letter()**: Now implement a function that takes in a word and returns a list with a letter inserted at every offset.\n",
    "\n",
    "**Step 1:** is the same as in `delete_letter()`\n",
    "\n",
    "**Step 2:** This can be a list comprehension of the form:  \n",
    "`[f(a,b,c) for a, b in splits if condition for c in string]`   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9768d501ade64311a8ed6e9eb433fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
    "# UNQ_C7 GRADED FUNCTION: inserts\n",
    "def insert_letter(word, verbose=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the input string/word\n",
    "    Output:\n",
    "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
    "    \"\"\"\n",
    "    letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    for i in range(len(word) + 1):\n",
    "        split_l.append(([word[:i], word[i:]]))\n",
    "\n",
    "    insert_l = [L + c + R for L, R in split_l for c in letters]\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
    "\n",
    "    return insert_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "061962c182f9482c8b1341b2a6f73cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word at \n",
      "split_l = [['', 'at'], ['a', 't'], ['at', '']] \n",
      "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz']\n",
      "Number of strings output by insert_letter('at') is 78\n"
     ]
    }
   ],
   "source": [
    "insert_l = insert_letter(\"at\", True)\n",
    "print(f\"Number of strings output by insert_letter('at') is {len(insert_l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edfd84aa00d4424a71141df99c55e72",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "\n",
    "```Python\n",
    "Input word at \n",
    "split_l = [('', 'at'), ('a', 't'), ('at', '')] \n",
    "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz']\n",
    "Number of strings output by insert_letter('at') is 78\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c55fba33aa346cf939c9cd632996673",
   "metadata": {},
   "source": [
    "#### Note 1\n",
    "\n",
    "If you get a split_l like this:\n",
    "```Python\n",
    "Input word at \n",
    "split_l = [('', 'at'), ('a', 't')] \n",
    "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt']\n",
    "Number of strings output by insert_letter('at') is 52\n",
    "```\n",
    "- Notice that split_l is missing the extra tuple ('at', '').  For insertion, we actually **WANT** this tuple.\n",
    "- The function is not creating all the desired output strings.\n",
    "- Check the range that you use for the for loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab13b4b6e2874167b7f2debb11dcd1d9",
   "metadata": {},
   "source": [
    "#### Note 2\n",
    "If you see this:\n",
    "```Python\n",
    "Input word at \n",
    "split_l = [('', 'at'), ('a', 't'), ('at', '')] \n",
    "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt']\n",
    "Number of strings output by insert_letter('at') is 52\n",
    "```\n",
    "\n",
    "- Even though you may have fixed the split_l so that it contains the tuple `('at', '')`, notice that you're still missing some output strings.\n",
    "    - Notice that it's missing strings such as 'ata', 'atb', 'atc' all the way to 'atz'.\n",
    "- To fix this, make sure that when you set insert_l, you allow the use of the empty string `''`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47d658866ccb404681cf21a4419000da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "w1_unittest.test_insert_letter(insert_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d973992396c4b758db40b17e80dc1fc",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Combining the Edits\n",
    "\n",
    "Now that you have implemented the string manipulations, you will create two functions that, given a string, will return all the possible single and double edits on that string. These will be `edit_one_letter()` and `edit_two_letters()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9cbe9d9a794dbd8aaa1fa72bce99a9",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>\n",
    "### 3.1 - Edit One Letter\n",
    "\n",
    "<a name='ex-8'></a>\n",
    "### Exercise 8 - edit_one_letter\n",
    "\n",
    "**Instructions**: Implement the `edit_one_letter` function to get all the possible edits that are one edit away from a word. The edits  consist of the replace, insert, delete, and optionally the switch operation. You should use the previous functions you have already implemented to complete this function. The 'switch' function  is a less common edit function, so its use will be selected by an \"allow_switches\" input argument.\n",
    "\n",
    "Note that those functions return *lists* while this function should return a *python set*. Utilizing a set eliminates any duplicate entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b434e0d67d894725aa1f6d707a143313",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> Each of the functions returns a list.  You can combine lists using the `+` operator. </li>\n",
    "    <li> To get unique strings (avoid duplicates), you can use the set() function. </li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "594a68b434714bab9e1df903f88edcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
    "# UNQ_C8 GRADED FUNCTION: edit_one_letter\n",
    "def edit_one_letter(word, allow_switches=True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
    "    Output:\n",
    "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
    "    \"\"\"\n",
    "    edit_one_set = set()\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    edit_one_set.update(delete_letter(word))\n",
    "    if allow_switches:\n",
    "        edit_one_set.update(switch_letter(word))\n",
    "        edit_one_set.update(replace_letter(word))\n",
    "        edit_one_set.update(insert_letter(word))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # return this as a set and not a list\n",
    "    return set(edit_one_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d59fedcae41437686ad1a71a1884d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word at \n",
      "edit_one_l \n",
      "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
      "\n",
      "The type of the returned object should be a set <class 'set'>\n",
      "Number of outputs from edit_one_letter('at') is 129\n"
     ]
    }
   ],
   "source": [
    "tmp_word = \"at\"\n",
    "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
    "# turn this into a list to sort it, in order to view it\n",
    "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
    "\n",
    "print(f\"input word {tmp_word} \\nedit_one_l \\n{tmp_edit_one_l}\\n\")\n",
    "print(f\"The type of the returned object should be a set {type(tmp_edit_one_set)}\")\n",
    "print(f\"Number of outputs from edit_one_letter('at') is {len(edit_one_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a36f4709894f8e822f9c383b5c8674",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "```CPP\n",
    "input word at \n",
    "edit_one_l \n",
    "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
    "\n",
    "The type of the returned object should be a set <class 'set'>\n",
    "Number of outputs from edit_one_letter('at') is 129\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13e578e05204494e9a74b868b4a9c0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "w1_unittest.test_edit_one_letter(edit_one_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472c087bdaf047c4bd2daf3102168774",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "### 3.2 - Edit Two Letters\n",
    "\n",
    "<a name='ex-9'></a>\n",
    "### Exercise 9 - edit_two_letters\n",
    "\n",
    "Now you can generalize this to implement to get two edits on a word. To do so, you would have to get all the possible edits on a single word and then for each modified word, you would have to modify it again. \n",
    "\n",
    "**Instructions**: Implement the `edit_two_letters` function that returns a set of words that are two edits away. Note that creating additional edits based on the `edit_one_letter` function may 'restore' some one_edits to zero or one edits. That is allowed here. This is accounted for in get_corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c11e5ea01d13400882806a9c4ab303ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x7fb075d74350>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(e2 for e1 in edit_one_letter(\"a\", allow_switches=True) for e2 in edit_one_letter(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0755c77c2af48ad9c17a637f99c96f7",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>You will likely want to take the union of two sets.</li>\n",
    "    <li>You can either use set.update() or use the '|' (or operator) to union two sets</li>\n",
    "    <li>See the documentation <a href=\"https://docs.python.org/2/library/sets.html\" > Python sets </a> for examples of using operators or functions of the Python set.</li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c01db64ab1c14c5599cb15ec16f03e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_one = edit_one_letter(\"a\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f9ba92a60e8d4a7c9e00b1317491f415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not w found\n",
      "na\n",
      "{'nwa', 'nna', 'nap', 'nma', 'npa', 'nea', 'n', 'nda', 'ns', 'za', 'nal', 'nae', 'ya', 'nja', 'ca', 'nva', 'nat', 'naa', 'ka', 'ea', 'aa', 'ni', 'gna', 'nl', 'nd', 'naf', 'sa', 'nak', 'naq', 'qna', 'vna', 'nb', 'tna', 'nka', 'nas', 'bna', 'nah', 'nj', 'nh', 'nc', 'nab', 'nua', 'nau', 'lna', 'nw', 'la', 'ena', 'nav', 'nx', 'ne', 'nt', 'ana', 'ma', 'cna', 'nia', 'nxa', 'ia', 'qa', 'nn', 'da', 'noa', 'nr', 'fa', 'nax', 'zna', 'nq', 'fna', 'nca', 'dna', 'nz', 'no', 'ua', 'wna', 'sna', 'nad', 'pna', 'nk', 'hna', 'pa', 'nza', 'rna', 'nra', 'yna', 'xna', 'nv', 'nai', 'nqa', 'nf', 'ny', 'nan', 'ta', 'nm', 'nar', 'ha', 'nam', 'ng', 'kna', 'ona', 'a', 'va', 'nac', 'naj', 'naz', 'wa', 'mna', 'nga', 'nya', 'ba', 'ina', 'nsa', 'nu', 'nba', 'nha', 'oa', 'nag', 'nay', 'una', 'ra', 'nao', 'an', 'xa', 'jna', 'np', 'nta', 'ga', 'nfa', 'nla', 'naw', 'ja'}\n",
      "ia\n",
      "{'iq', 'na', 'iba', 'iao', 'ida', 'ig', 'in', 'bia', 'za', 'il', 'ya', 'xia', 'ipa', 'ca', 'iia', 'iaz', 'yia', 'ip', 'ea', 'ka', 'sia', 'aa', 'ial', 'iax', 'ica', 'ib', 'eia', 'ija', 'ita', 'ila', 'sa', 'qia', 'iu', 'iai', 'it', 'ian', 'iha', 'iaa', 'iqa', 'uia', 'i', 'iaj', 'lia', 'iwa', 'im', 'ria', 'gia', 'iea', 'io', 'ie', 'ika', 'ixa', 'iah', 'iad', 'id', 'iya', 'jia', 'ai', 'la', 'cia', 'iae', 'mia', 'iaf', 'ma', 'iar', 'ij', 'nia', 'qa', 'iaw', 'iac', 'iw', 'iab', 'iza', 'da', 'fa', 'aia', 'iga', 'ih', 'hia', 'ima', 'iag', 'iy', 'ua', 'fia', 'iaq', 'pia', 'iat', 'iak', 'iay', 'ik', 'via', 'ias', 'pa', 'ioa', 'if', 'iz', 'is', 'ta', 'ii', 'iv', 'tia', 'ix', 'ha', 'oia', 'a', 'va', 'iua', 'iap', 'ifa', 'zia', 'wa', 'iva', 'ba', 'ina', 'iau', 'dia', 'iav', 'oa', 'kia', 'wia', 'ira', 'ra', 'ir', 'ic', 'xa', 'isa', 'ga', 'iam', 'ja'}\n",
      "z\n",
      "{'', 'q', 'o', 'zr', 'v', 'c', 'n', 'za', 'zc', 'zq', 'cz', 'hz', 'y', 'zt', 'nz', 'p', 'f', 'zz', 'zy', 'zg', 'zu', 'b', 'lz', 'm', 'zx', 'yz', 'pz', 'zf', 'ze', 'zj', 'zv', 'k', 'zb', 'wz', 'g', 'zk', 's', 'mz', 'iz', 'dz', 'w', 'zh', 'vz', 'sz', 't', 'zs', 'xz', 'kz', 'zp', 'a', 'oz', 'd', 'jz', 'i', 'zi', 'gz', 'zd', 'zm', 'tz', 'ez', 'r', 'zn', 'l', 'qz', 'rz', 'zo', 'j', 'e', 'az', 'zl', 'h', 'bz', 'u', 'uz', 'zw', 'x', 'fz'}\n",
      "qa\n",
      "{'qy', 'qaj', 'na', 'qak', 'mqa', 'dqa', 'qaq', 'za', 'qaa', 'ya', 'ca', 'qd', 'qea', 'qla', 'qaf', 'qam', 'ka', 'ea', 'qm', 'aa', 'qb', 'qw', 'qwa', 'qta', 'qf', 'qax', 'sa', 'qg', 'qha', 'qia', 'qxa', 'xqa', 'qna', 'qas', 'qaz', 'qao', 'jqa', 'qai', 'qfa', 'iqa', 'qp', 'tqa', 'qra', 'vqa', 'qo', 'uqa', 'qad', 'qua', 'qz', 'eqa', 'qv', 'qah', 'qav', 'la', 'qs', 'qda', 'qpa', 'qba', 'pqa', 'ma', 'rqa', 'qk', 'qq', 'kqa', 'qal', 'aq', 'ia', 'qi', 'qsa', 'q', 'da', 'qu', 'fa', 'qan', 'gqa', 'ua', 'qh', 'lqa', 'qga', 'qj', 'wqa', 'hqa', 'sqa', 'pa', 'qat', 'qar', 'oqa', 'cqa', 'qag', 'qx', 'nqa', 'ta', 'qab', 'zqa', 'ha', 'a', 'bqa', 'va', 'qr', 'qva', 'qae', 'qau', 'qe', 'qza', 'qac', 'qt', 'qoa', 'qay', 'wa', 'yqa', 'ba', 'qc', 'qn', 'qca', 'oa', 'qap', 'qma', 'ra', 'qaw', 'qja', 'aqa', 'qya', 'xa', 'qka', 'ql', 'fqa', 'ga', 'qqa', 'ja'}\n",
      "aq\n",
      "{'iq', 'aqf', 'aqj', 'qaq', 'axq', 'aqu', 'aqs', 'aqz', 'vaq', 'zq', 'aaq', 'oq', 'cq', 'jaq', 'ayq', 'awq', 'al', 'aqq', 'xq', 'aqh', 'ak', 'aa', 'fq', 'aqv', 'rq', 'abq', 'aqp', 'kaq', 'haq', 'naq', 'eaq', 'ab', 'anq', 'laq', 'ad', 'afq', 'am', 'agq', 'aqw', 'raq', 'arq', 'alq', 'tq', 'eq', 'gq', 'daq', 'taq', 'ax', 'uq', 'ar', 'avq', 'aqy', 'mq', 'hq', 'wq', 'ai', 'ajq', 'jq', 'aqo', 'akq', 'qq', 'qa', 'aqm', 'q', 'vq', 'zaq', 'xaq', 'dq', 'aqr', 'av', 'saq', 'nq', 'ahq', 'asq', 'aoq', 'baq', 'aqn', 'iaq', 'atq', 'af', 'faq', 'aiq', 'ac', 'paq', 'aeq', 'adq', 'ao', 'bq', 'aj', 'ap', 'aqt', 'aw', 'auq', 'a', 'aql', 'ah', 'aqg', 'acq', 'lq', 'caq', 'oaq', 'aqi', 'maq', 'kq', 'aqk', 'ae', 'ay', 'aqb', 'aqd', 'aqe', 'apq', 'uaq', 'amq', 'ag', 'an', 'pq', 'az', 'yaq', 'aqa', 'aqx', 'yq', 'azq', 'au', 'as', 'sq', 'waq', 'at', 'aqc', 'gaq'}\n",
      "q\n",
      "{'', 'iq', 'qy', 'qq', 'aq', 'z', 'qa', 'qi', 'o', 'v', 'vq', 'c', 'n', 'qu', 'dq', 'zq', 'nq', 'y', 'p', 'f', 'b', 'oq', 'qh', 'cq', 'm', 'qd', 'xq', 'qj', 'qm', 'k', 'fq', 'qb', 'qw', 'g', 's', 'bq', 'qx', 'w', 'rq', 'qf', 'qg', 't', 'a', 'qr', 'd', 'qe', 'lq', 'qt', 'i', 'qp', 'kq', 'tq', 'eq', 'gq', 'qc', 'qn', 'qo', 'uq', 'r', 'l', 'qz', 'j', 'mq', 'hq', 'e', 'wq', 'qv', 'pq', 'yq', 'jq', 'qs', 'h', 'u', 'sq', 'ql', 'x', 'qk'}\n",
      "o\n",
      "{'', 'ot', 'co', 'lo', 'z', 'ol', 'jo', 'q', 'to', 'v', 'oc', 'c', 'n', 'og', 'om', 'mo', 'oi', 'y', 'of', 'p', 'f', 'no', 'b', 'yo', 'oq', 'm', 'do', 'xo', 'fo', 'k', 'ob', 'g', 'ao', 'ox', 'go', 'oe', 'uo', 'ou', 's', 'ro', 'oj', 'w', 'ho', 'on', 'vo', 't', 'or', 'ko', 'eo', 'a', 'bo', 'oz', 'oy', 'od', 'd', 'so', 'i', 'ov', 'po', 'io', 'qo', 'oa', 'wo', 'oo', 'r', 'os', 'l', 'zo', 'j', 'e', 'ok', 'op', 'h', 'u', 'oh', 'x', 'ow'}\n",
      "v\n",
      "{'', 'z', 'vt', 'vm', 'vs', 'q', 'o', 'pv', 'vq', 'bv', 'vd', 'c', 'n', 'vi', 'vf', 'av', 'vj', 'vp', 'hv', 'dv', 'vv', 'y', 'p', 'f', 've', 'b', 'jv', 'm', 'gv', 'uv', 'zv', 'k', 'g', 'cv', 'rv', 's', 'vk', 'nv', 'sv', 'w', 'vw', 'kv', 'iv', 'vz', 'vo', 't', 'vb', 'vl', 'vy', 'a', 'vc', 'va', 'wv', 'd', 'i', 'lv', 'ev', 'ov', 'vg', 'yv', 'mv', 'vu', 'vr', 'r', 'tv', 'l', 'xv', 'vn', 'j', 'qv', 'e', 'vh', 'vx', 'fv', 'h', 'u', 'x'}\n",
      "c\n",
      "{'', 'co', 'z', 'q', 'o', 'v', 'oc', 'n', 'cx', 'cu', 'zc', 'mc', 'cz', 'cn', 'y', 'yc', 'ca', 'p', 'f', 'jc', 'xc', 'b', 'cw', 'cq', 'm', 'cm', 'gc', 'cy', 'ac', 'bc', 'k', 'wc', 'cb', 'ch', 'g', 'tc', 'cv', 'ck', 'rc', 's', 'cl', 'cj', 'w', 'dc', 't', 'lc', 'sc', 'pc', 'ct', 'a', 'vc', 'cr', 'fc', 'd', 'cf', 'i', 'hc', 'nc', 'cc', 'cg', 'cs', 'qc', 'ci', 'cp', 'ec', 'r', 'l', 'ce', 'j', 'kc', 'e', 'ic', 'uc', 'h', 'u', 'x', 'cd'}\n",
      "n\n",
      "{'', 'na', 'z', 'hn', 'q', 'nn', 'o', 'v', 'gn', 'kn', 'sn', 'c', 'in', 'ns', 'jn', 'nr', 'nq', 'xn', 'cn', 'y', 'nz', 'p', 'f', 'no', 'b', 'm', 'dn', 'nk', 'k', 'pn', 'g', 'yn', 'ni', 's', 'nv', 'wn', 'nl', 'nf', 'ny', 'un', 'w', 'nd', 'on', 't', 'nm', 'nb', 'en', 'bn', 'fn', 'ng', 'a', 'd', 'nj', 'i', 'nh', 'nc', 'qn', 'tn', 'nu', 'r', 'zn', 'l', 'ln', 'vn', 'j', 'mn', 'an', 'e', 'rn', 'nw', 'np', 'h', 'nx', 'u', 'ne', 'nt', 'x'}\n",
      "da\n",
      "{'na', 'dag', 'dad', 'dqa', 'ida', 'dav', 'mda', 'nda', 'dza', 'za', 'dar', 'day', 'ya', 'dpa', 'ca', 'dae', 'ka', 'ea', 'dxa', 'aa', 'dj', 'dah', 'dsa', 'dfa', 'jda', 'das', 'dz', 'di', 'dr', 'dwa', 'sa', 'dd', 'dk', 'ad', 'dja', 'dta', 'dva', 'doa', 'bda', 'sda', 'lda', 'dl', 'xda', 'daq', 'dam', 'dat', 'dea', 'dx', 'dga', 'oda', 'rda', 'dao', 'daw', 'ada', 'daf', 'dca', 'dla', 'dap', 'la', 'qda', 'dm', 'dt', 'daz', 'dak', 'ma', 'cda', 'ia', 'qa', 'dan', 'pda', 'dab', 'dai', 'ds', 'fa', 'dq', 'tda', 'dma', 'dv', 'zda', 'dna', 'dal', 'dy', 'dax', 'ua', 'db', 'dua', 'dn', 'do', 'vda', 'de', 'pa', 'daa', 'dg', 'dba', 'uda', 'ta', 'dc', 'dya', 'dda', 'yda', 'ha', 'dau', 'a', 'va', 'd', 'hda', 'gda', 'kda', 'dw', 'wa', 'ba', 'fda', 'dia', 'dac', 'oa', 'dra', 'daj', 'df', 'ra', 'dha', 'eda', 'dka', 'xa', 'dh', 'wda', 'dp', 'ga', 'du', 'ja'}\n",
      "za\n",
      "{'na', 'vza', 'mza', 'zr', 'zab', 'dza', 'zq', 'ya', 'zta', 'aza', 'zfa', 'zt', 'ca', 'zy', 'zz', 'tza', 'zar', 'zu', 'zak', 'zax', 'bza', 'zf', 'ze', 'ka', 'ea', 'zv', 'aa', 'zb', 'zk', 'zza', 'zay', 'zha', 'sa', 'wza', 'zaf', 'zs', 'zac', 'sza', 'zav', 'zas', 'zp', 'jza', 'rza', 'zam', 'zpa', 'zi', 'zau', 'zca', 'zsa', 'zea', 'zm', 'zn', 'zwa', 'zka', 'yza', 'zag', 'la', 'zao', 'lza', 'ma', 'zap', 'ia', 'z', 'qa', 'zal', 'zad', 'zva', 'xza', 'iza', 'da', 'zaq', 'fa', 'uza', 'zc', 'zna', 'gza', 'zda', 'ua', 'pza', 'zg', 'zaj', 'zx', 'zj', 'zra', 'pa', 'nza', 'zan', 'zoa', 'ta', 'zh', 'zai', 'fza', 'zah', 'zba', 'kza', 'oza', 'zqa', 'ha', 'zma', 'zga', 'a', 'cza', 'va', 'zja', 'qza', 'zla', 'zia', 'wa', 'zaa', 'ba', 'zae', 'zya', 'zd', 'zxa', 'zaz', 'oa', 'ra', 'zo', 'zua', 'az', 'zat', 'zaw', 'eza', 'xa', 'zl', 'hza', 'zw', 'ga', 'ja'}\n",
      "fa\n",
      "{'na', 'kfa', 'za', 'ya', 'ffa', 'zfa', 'ca', 'f', 'fat', 'foa', 'ff', 'ka', 'ea', 'xfa', 'fw', 'fo', 'aa', 'fq', 'wfa', 'fab', 'ft', 'fr', 'fap', 'tfa', 'faz', 'fd', 'fga', 'dfa', 'fya', 'pfa', 'fan', 'ufa', 'sa', 'fwa', 'fu', 'jfa', 'fy', 'faj', 'fay', 'fh', 'fad', 'ofa', 'fp', 'fla', 'qfa', 'fau', 'fc', 'fb', 'fac', 'fal', 'cfa', 'fra', 'efa', 'fg', 'fl', 'gfa', 'fam', 'la', 'ma', 'fj', 'ia', 'qa', 'vfa', 'hfa', 'fas', 'da', 'fao', 'fna', 'fk', 'ua', 'fia', 'fag', 'af', 'lfa', 'faw', 'fxa', 'faq', 'fha', 'pa', 'fav', 'fak', 'fae', 'fah', 'far', 'ta', 'fza', 'fax', 'fs', 'fja', 'fn', 'afa', 'fea', 'faa', 'ha', 'fi', 'fpa', 'fva', 'a', 'va', 'faf', 'rfa', 'fm', 'fsa', 'ifa', 'sfa', 'fka', 'mfa', 'wa', 'yfa', 'fta', 'ba', 'fda', 'oa', 'ra', 'fai', 'fua', 'bfa', 'fv', 'xa', 'fca', 'fma', 'fx', 'fba', 'fqa', 'ga', 'nfa', 'fe', 'ja', 'fz'}\n",
      "av\n",
      "{'lav', 'pav', 'axv', 'bv', 'anv', 'dav', 'kav', 'hv', 'vv', 'avg', 'al', 'aiv', 'avh', 'ak', 'zv', 'aa', 'avv', 'aqv', 'avt', 'cv', 'avl', 'avm', 'atv', 'afv', 'mav', 'aav', 'sav', 'kv', 'avf', 'ab', 'ad', 'zav', 'am', 'akv', 'aov', 'avk', 'alv', 'avr', 'avb', 'oav', 'avj', 'rav', 'awv', 'avc', 'mv', 'ax', 'bav', 'adv', 'ar', 'tv', 'avq', 'qv', 'uav', 'ai', 'avz', 'qav', 'avn', 'ajv', 'nav', 'aev', 'ahv', 'avw', 'agv', 'auv', 'ayv', 'arv', 'aq', 'eav', 'v', 'pv', 'yav', 'dv', 'hav', 'jv', 'af', 'avu', 'gv', 'avo', 'uv', 'avs', 'avd', 'ac', 'abv', 'fav', 'rv', 'ao', 'nv', 'aj', 'sv', 'iv', 'gav', 'ap', 'asv', 'aw', 'a', 'va', 'wv', 'ah', 'cav', 'jav', 'lv', 'tav', 'apv', 'ev', 'ov', 'ae', 'ay', 'yv', 'ava', 'wav', 'iav', 'avp', 'acv', 'ave', 'xv', 'ag', 'azv', 'an', 'az', 'fv', 'au', 'avx', 'avy', 'xav', 'as', 'vav', 'at', 'amv', 'avi'}\n",
      "ya\n",
      "{'yha', 'na', 'yea', 'yax', 'yag', 'yta', 'yan', 'yw', 'za', 'bya', 'yc', 'ca', 'yt', 'yo', 'yy', 'vya', 'yz', 'yia', 'yam', 'ka', 'ea', 'yas', 'cya', 'aa', 'yn', 'kya', 'yaa', 'fya', 'yab', 'sa', 'yra', 'yk', 'yl', 'yva', 'yat', 'tya', 'yah', 'ym', 'yai', 'ysa', 'yal', 'yga', 'yao', 'yr', 'yar', 'yaz', 'yza', 'iya', 'yaj', 'yp', 'gya', 'la', 'yxa', 'pya', 'ma', 'yi', 'yj', 'yya', 'ywa', 'yay', 'ia', 'qa', 'yaw', 'yac', 'yau', 'ye', 'da', 'fa', 'yav', 'aya', 'y', 'ua', 'yak', 'yja', 'yx', 'yla', 'ys', 'yoa', 'pa', 'jya', 'ypa', 'yna', 'yu', 'ta', 'yca', 'yg', 'dya', 'yb', 'yka', 'rya', 'eya', 'yda', 'ha', 'sya', 'a', 'va', 'oya', 'yba', 'yad', 'yaf', 'lya', 'wya', 'yh', 'wa', 'yqa', 'yfa', 'ay', 'nya', 'ba', 'yv', 'zya', 'yf', 'oa', 'yua', 'yae', 'ra', 'yaq', 'qya', 'yma', 'mya', 'yap', 'xa', 'yq', 'yd', 'hya', 'xya', 'uya', 'ga', 'ja'}\n",
      "y\n",
      "{'', 'qy', 'yj', 'sy', 'z', 'q', 'o', 'v', 'ye', 'c', 'n', 'ey', 'py', 'yw', 'ya', 'uy', 'yc', 'dy', 'p', 'f', 'zy', 'yt', 'iy', 'b', 'yo', 'yy', 'yx', 'm', 'hy', 'yz', 'ys', 'cy', 'k', 'g', 'yn', 'jy', 's', 'yu', 'ty', 'ny', 'gy', 'w', 'yg', 'yk', 't', 'yl', 'yb', 'fy', 'ym', 'vy', 'ly', 'a', 'oy', 'ry', 'd', 'i', 'yh', 'ay', 'yv', 'yf', 'xy', 'yr', 'by', 'r', 'l', 'j', 'e', 'yp', 'my', 'yq', 'yd', 'h', 'u', 'ky', 'x', 'wy', 'yi'}\n",
      "ca\n",
      "{'na', 'co', 'cak', 'cja', 'c', 'cx', 'za', 'cu', 'ya', 'jca', 'cn', 'cua', 'caf', 'cq', 'caj', 'ka', 'ea', 'cya', 'aa', 'cb', 'cv', 'ck', 'ica', 'pca', 'aca', 'can', 'sca', 'cka', 'sa', 'caz', 'cma', 'ct', 'cr', 'cf', 'cxa', 'cc', 'cg', 'cs', 'cfa', 'cab', 'cva', 'zca', 'kca', 'cp', 'cla', 'dca', 'cea', 'la', 'cae', 'cia', 'cta', 'oca', 'hca', 'gca', 'ma', 'csa', 'cda', 'cd', 'cna', 'cba', 'cag', 'ia', 'qa', 'cga', 'cah', 'rca', 'car', 'uca', 'da', 'fa', 'xca', 'cz', 'nca', 'ua', 'cw', 'cay', 'cm', 'vca', 'cra', 'cy', 'cao', 'ac', 'cax', 'ch', 'pa', 'cha', 'cac', 'cpa', 'cca', 'cqa', 'cad', 'cl', 'eca', 'cj', 'cat', 'ta', 'yca', 'ha', 'cam', 'a', 'cza', 'va', 'cas', 'caw', 'lca', 'cav', 'caa', 'caq', 'wa', 'cwa', 'cal', 'ba', 'qca', 'bca', 'ci', 'oa', 'cai', 'ce', 'ra', 'mca', 'tca', 'coa', 'xa', 'fca', 'cau', 'ga', 'ja', 'wca', 'cap'}\n",
      "p\n",
      "{'', 'z', 'q', 'o', 'v', 'pv', 'c', 'n', 'py', 'vp', 'pd', 'pp', 'y', 'lp', 'xp', 'f', 'b', 'm', 'pz', 'ip', 'sp', 'k', 'pn', 'pa', 'g', 'ph', 's', 'pm', 'wp', 'px', 'w', 'pu', 'pl', 'ap', 't', 'pr', 'pg', 'gp', 'zp', 'jp', 'fp', 'tp', 'pw', 'pj', 'hp', 'pb', 'ep', 'pe', 'pc', 'mp', 'a', 'd', 'pt', 'i', 'qp', 'kp', 'bp', 'up', 'po', 'rp', 'cp', 'r', 'l', 'pk', 'j', 'pi', 'ps', 'e', 'pq', 'yp', 'op', 'np', 'h', 'u', 'dp', 'x', 'pf'}\n",
      "f\n",
      "{'', 'z', 'q', 'o', 'v', 'c', 'n', 'fa', 'vf', 'wf', 'y', 'of', 'p', 'fk', 'bf', 'gf', 'b', 'af', 'm', 'ff', 'zf', 'fw', 'fo', 'k', 'fq', 'g', 'ft', 'fr', 'fd', 's', 'kf', 'if', 'nf', 'w', 'qf', 'fu', 't', 'fs', 'fy', 'fh', 'fn', 'sf', 'fp', 'fi', 'mf', 'a', 'fc', 'd', 'cf', 'fb', 'fm', 'i', 'uf', 'lf', 'xf', 'yf', 'fg', 'fz', 'df', 'r', 'l', 'ef', 'hf', 'fl', 'j', 'e', 'jf', 'fv', 'rf', 'h', 'u', 'fx', 'tf', 'x', 'fe', 'pf', 'fj'}\n",
      "ua\n",
      "{'na', 'uwa', 'uva', 'uj', 'uh', 'za', 'uka', 'ya', 'vua', 'usa', 'uy', 'cua', 'lua', 'ca', 'uja', 'ura', 'ui', 'uua', 'uat', 'gua', 'uma', 'ka', 'ea', 'ue', 'aa', 'ul', 'uas', 'uai', 'uah', 'uo', 'uam', 'tua', 'ufa', 'sa', 'sua', 'uac', 'uia', 'hua', 'us', 'uoa', 'uxa', 'nua', 'up', 'uf', 'wua', 'uga', 'uax', 'uqa', 'uq', 'qua', 'uay', 'mua', 'uav', 'uha', 'la', 'aua', 'uk', 'uan', 'oua', 'ma', 'ia', 'qa', 'uca', 'uap', 'da', 'eua', 'uak', 'fa', 'uza', 'uta', 'ur', 'uao', 'ula', 'dua', 'uw', 'bua', 'uv', 'ut', 'uaj', 'uu', 'uea', 'uaa', 'ud', 'pa', 'xua', 'pua', 'uda', 'un', 'ta', 'uab', 'ub', 'uaz', 'upa', 'ha', 'uae', 'a', 'jua', 'va', 'iua', 'ual', 'rua', 'wa', 'uad', 'um', 'ba', 'oa', 'ux', 'yua', 'una', 'ra', 'uaq', 'fua', 'ug', 'zua', 'uaf', 'kua', 'uba', 'uc', 'xa', 'uag', 'uau', 'au', 'uz', 'u', 'uya', 'ga', 'uaw', 'ja', 'uar'}\n",
      "b\n",
      "{'', 'z', 'q', 'be', 'o', 'v', 'sb', 'bv', 'c', 'n', 'bb', 'bd', 'y', 'p', 'f', 'bf', 'jb', 'db', 'm', 'bc', 'ob', 'k', 'cb', 'qb', 'g', 'zb', 's', 'ib', 'bq', 'bt', 'w', 'bl', 'bx', 'bm', 'ab', 't', 'yb', 'vb', 'ub', 'nb', 'bn', 'wb', 'bh', 'pb', 'a', 'bj', 'bo', 'lb', 'd', 'fb', 'i', 'kb', 'mb', 'rb', 'bp', 'bw', 'ba', 'bi', 'tb', 'bk', 'by', 'r', 'l', 'j', 'eb', 'e', 'xb', 'h', 'br', 'bz', 'gb', 'u', 'x', 'bg', 'hb', 'bs', 'bu'}\n",
      "af\n",
      "{'aqf', 'afi', 'afm', 'paf', 'baf', 'aif', 'xaf', 'afe', 'aef', 'raf', 'abf', 'adf', 'f', 'gaf', 'caf', 'al', 'ff', 'qaf', 'zf', 'aft', 'ak', 'aa', 'ahf', 'taf', 'atf', 'jaf', 'afb', 'kf', 'waf', 'axf', 'afv', 'qf', 'naf', 'zaf', 'eaf', 'avf', 'ab', 'afs', 'acf', 'ad', 'afz', 'afq', 'am', 'afc', 'afd', 'mf', 'afu', 'cf', 'laf', 'azf', 'afy', 'uf', 'alf', 'lf', 'xf', 'ax', 'ar', 'afr', 'afj', 'daf', 'ai', 'agf', 'rf', 'akf', 'iaf', 'tf', 'afl', 'aq', 'ajf', 'fa', 'vf', 'wf', 'av', 'afk', 'auf', 'afn', 'of', 'oaf', 'bf', 'gf', 'aaf', 'apf', 'ac', 'ao', 'if', 'aof', 'nf', 'maf', 'aj', 'ayf', 'ap', 'aw', 'afa', 'sf', 'afp', 'afh', 'a', 'aff', 'afo', 'ah', 'faf', 'afx', 'yaf', 'afw', 'ae', 'ay', 'kaf', 'yf', 'haf', 'arf', 'df', 'ef', 'hf', 'ag', 'an', 'uaf', 'az', 'saf', 'jf', 'anf', 'awf', 'amf', 'asf', 'vaf', 'au', 'as', 'afg', 'at', 'pf'}\n",
      "m\n",
      "{'', 'z', 'vm', 'q', 'o', 'v', 'mm', 'c', 'n', 'mt', 'om', 'mc', 'em', 'km', 'md', 'mo', 'y', 'p', 'f', 'wm', 'hm', 'b', 'jm', 'sm', 'cm', 'mx', 'qm', 'k', 'g', 'mw', 's', 'pm', 'mz', 'mg', 'w', 'bm', 't', 'mj', 'nm', 'mh', 'mr', 'me', 'am', 'ym', 'mf', 'mp', 'a', 'd', 'fm', 'i', 'gm', 'mb', 'im', 'um', 'mv', 'tm', 'zm', 'r', 'l', 'j', 'mq', 'mn', 'e', 'ml', 'mu', 'my', 'rm', 'h', 'mk', 'u', 'ms', 'dm', 'xm', 'x', 'ma', 'mi', 'lm'}\n",
      "al\n",
      "{'alb', 'hal', 'als', 'kl', 'alm', 'ala', 'nal', 'ral', 'il', 'sl', 'aly', 'kal', 'ahl', 'akl', 'alz', 'rl', 'gl', 'ael', 'ak', 'aa', 'val', 'ul', 'ial', 'avl', 'awl', 'eal', 'nl', 'alx', 'xl', 'ab', 'yl', 'alk', 'alc', 'ad', 'el', 'am', 'aal', 'wl', 'alv', 'pal', 'alr', 'alo', 'fal', 'arl', 'ale', 'dl', 'alq', 'alt', 'aml', 'bal', 'xal', 'alf', 'ax', 'yal', 'alh', 'ar', 'l', 'oal', 'ayl', 'tal', 'alp', 'fl', 'aol', 'ml', 'ai', 'la', 'hl', 'alw', 'afl', 'ajl', 'qal', 'aq', 'zal', 'ol', 'alu', 'll', 'tl', 'sal', 'av', 'gal', 'aul', 'dal', 'adl', 'af', 'ail', 'azl', 'ac', 'ali', 'alg', 'anl', 'ao', 'cl', 'alj', 'lal', 'axl', 'aj', 'bl', 'pl', 'ap', 'mal', 'aw', 'vl', 'asl', 'all', 'a', 'aql', 'agl', 'ah', 'jal', 'ual', 'cal', 'ae', 'ay', 'ald', 'acl', 'jl', 'apl', 'ag', 'an', 'az', 'wal', 'abl', 'zl', 'atl', 'au', 'aln', 'as', 'ql', 'at'}\n",
      "ka\n",
      "{'na', 'gka', 'kl', 'kn', 'kfa', 'kj', 'aka', 'za', 'uka', 'kav', 'kva', 'km', 'ya', 'kal', 'ca', 'kh', 'ke', 'ea', 'ak', 'pka', 'aa', 'k', 'kap', 'kab', 'kya', 'kf', 'kpa', 'vka', 'cka', 'sa', 'kaq', 'kv', 'hka', 'ko', 'nka', 'rka', 'kt', 'wka', 'kja', 'kac', 'kae', 'kd', 'kma', 'kak', 'kax', 'ika', 'tka', 'kca', 'kka', 'kwa', 'eka', 'zka', 'kc', 'kx', 'la', 'kaj', 'kea', 'ksa', 'ma', 'kam', 'ku', 'kqa', 'kao', 'ia', 'qa', 'lka', 'kha', 'kat', 'da', 'fa', 'kah', 'kai', 'kla', 'kk', 'jka', 'kxa', 'kad', 'ua', 'ks', 'pa', 'kaa', 'kaz', 'kra', 'kr', 'ta', 'kay', 'kza', 'yka', 'kga', 'ska', 'kau', 'kz', 'kaw', 'mka', 'ha', 'kba', 'koa', 'kna', 'a', 'va', 'kta', 'kda', 'oka', 'bka', 'fka', 'kas', 'kq', 'kb', 'kp', 'wa', 'ba', 'kaf', 'kan', 'xka', 'oa', 'kia', 'ki', 'ra', 'kua', 'dka', 'kag', 'xa', 'kar', 'qka', 'ky', 'kg', 'ga', 'kw', 'ja'}\n",
      "ea\n",
      "{'na', 'yea', 'eae', 'ead', 'eoa', 'nea', 'ey', 'za', 'eap', 'ear', 'wea', 'ya', 'er', 'gea', 'xea', 'ca', 'ee', 'epa', 'qea', 'eab', 'ka', 'ek', 'aa', 'ed', 'ex', 'ela', 'eal', 'ega', 'eia', 'eai', 'sa', 'eaf', 'es', 'eaq', 'en', 'el', 'eo', 'esa', 'ep', 'ean', 'eha', 'eas', 'eba', 'eah', 'eq', 'iea', 'bea', 'eao', 'efa', 'eau', 'dea', 'zea', 'eka', 'ewa', 'et', 'oea', 'eqa', 'e', 'eaj', 'cea', 'eax', 'eaz', 'la', 'ena', 'kea', 'eaa', 'eja', 'ma', 'ia', 'qa', 'eav', 'aea', 'vea', 'da', 'eua', 'fa', 'em', 'eva', 'pea', 'eu', 'ua', 'eay', 'uea', 'sea', 'eag', 'pa', 'mea', 'eaw', 'eca', 'eh', 'eg', 'ta', 'ew', 'ej', 'eya', 'fea', 'ha', 'tea', 'a', 'va', 'lea', 'eat', 'ev', 'wa', 'ei', 'ae', 'ba', 'rea', 'oa', 'ec', 'ez', 'eac', 'ef', 'era', 'hea', 'ra', 'eb', 'eza', 'eam', 'eda', 'xa', 'exa', 'eak', 'ga', 'jea', 'eea', 'eta', 'ja', 'ema'}\n",
      "ak\n",
      "{'qak', 'atk', 'oak', 'cak', 'lak', 'ahk', 'aka', 'aak', 'akr', 'awk', 'pak', 'zak', 'akl', 'akm', 'akx', 'al', 'jk', 'ka', 'ank', 'aa', 'k', 'ek', 'zk', 'ck', 'aki', 'vak', 'adk', 'xak', 'sak', 'yk', 'dk', 'nak', 'wak', 'ab', 'alk', 'ad', 'am', 'akv', 'gk', 'avk', 'akp', 'wk', 'kak', 'mak', 'akz', 'akd', 'ax', 'jak', 'agk', 'aok', 'ar', 'akg', 'akn', 'pk', 'akj', 'ok', 'hak', 'ai', 'abk', 'aky', 'uk', 'akw', 'akf', 'dak', 'akq', 'qk', 'akc', 'akt', 'aq', 'aku', 'ark', 'sk', 'akb', 'bak', 'rk', 'uak', 'ake', 'av', 'afk', 'aks', 'kk', 'apk', 'azk', 'fk', 'yak', 'af', 'iak', 'hk', 'ik', 'ask', 'auk', 'ac', 'nk', 'ack', 'fak', 'ao', 'vk', 'aj', 'axk', 'tk', 'ap', 'ajk', 'aw', 'gak', 'amk', 'aek', 'a', 'ah', 'tak', 'aqk', 'ae', 'ay', 'ayk', 'akh', 'bk', 'ako', 'lk', 'aik', 'ag', 'an', 'az', 'rak', 'akk', 'mk', 'au', 'eak', 'as', 'xk', 'at'}\n",
      "ac\n",
      "{'aac', 'acy', 'atc', 'c', 'mc', 'acs', 'acw', 'yc', 'ca', 'jac', 'jc', 'al', 'gc', 'axc', 'ak', 'bc', 'aa', 'wc', 'bac', 'acd', 'aca', 'gac', 'acg', 'anc', 'ab', 'zac', 'alc', 'acf', 'ad', 'acj', 'am', 'afc', 'mac', 'vc', 'uac', 'aci', 'fc', 'kac', 'fac', 'nc', 'cc', 'avc', 'ax', 'azc', 'ar', 'aec', 'asc', 'kc', 'ajc', 'ahc', 'ai', 'acx', 'akc', 'acr', 'aic', 'aq', 'sac', 'yac', 'vac', 'awc', 'acn', 'tac', 'iac', 'oc', 'agc', 'acz', 'oac', 'abc', 'zc', 'av', 'acc', 'xc', 'af', 'ace', 'auc', 'amc', 'acp', 'arc', 'ack', 'tc', 'acm', 'cac', 'ayc', 'ao', 'rc', 'aco', 'aj', 'aoc', 'dc', 'ap', 'lc', 'aw', 'sc', 'ach', 'pc', 'pac', 'acb', 'a', 'acu', 'nac', 'ah', 'apc', 'qac', 'acq', 'hc', 'ae', 'ay', 'hac', 'qc', 'dac', 'acv', 'ec', 'eac', 'acl', 'ag', 'act', 'an', 'lac', 'az', 'wac', 'adc', 'ic', 'uc', 'au', 'xac', 'as', 'rac', 'at', 'aqc'}\n",
      "k\n",
      "{'', 'z', 'q', 'o', 'v', 'kl', 'kn', 'sk', 'kj', 'c', 'n', 'rk', 'km', 'kk', 'y', 'kh', 'p', 'f', 'fk', 'b', 'm', 'ke', 'hk', 'ik', 'jk', 'ka', 'ak', 'ks', 'nk', 'ek', 'g', 'zk', 'ck', 's', 'vk', 'kf', 'kr', 'w', 'yk', 'kv', 'dk', 't', 'tk', 'ko', 'kz', 'a', 'gk', 'kt', 'd', 'kd', 'i', 'wk', 'kq', 'kb', 'kp', 'bk', 'lk', 'r', 'l', 'ki', 'pk', 'j', 'kc', 'e', 'ok', 'kx', 'uk', 'h', 'mk', 'u', 'ky', 'kg', 'kw', 'x', 'xk', 'ku', 'qk'}\n",
      "aa\n",
      "{'na', 'aar', 'aac', 'aka', 'taa', 'aad', 'xaa', 'za', 'ala', 'aak', 'qaa', 'ya', 'aza', 'ca', 'aaq', 'naa', 'al', 'aap', 'aja', 'ka', 'ea', 'ak', 'aa', 'yaa', 'aca', 'aao', 'waa', 'aax', 'aav', 'sa', 'ab', 'ad', 'am', 'aab', 'aal', 'aaj', 'iaa', 'aha', 'aaa', 'aga', 'aah', 'ax', 'raa', 'laa', 'aae', 'oaa', 'ar', 'ada', 'ai', 'aaz', 'la', 'aua', 'eaa', 'ana', 'ma', 'aq', 'ia', 'qa', 'aea', 'da', 'jaa', 'fa', 'av', 'aia', 'awa', 'baa', 'aya', 'saa', 'ua', 'paa', 'ara', 'af', 'aaf', 'ac', 'uaa', 'pa', 'aoa', 'daa', 'vaa', 'ao', 'aai', 'kaa', 'ama', 'aj', 'ta', 'ata', 'ap', 'asa', 'aw', 'aay', 'haa', 'afa', 'faa', 'ha', 'aau', 'a', 'va', 'aag', 'ah', 'caa', 'aaw', 'wa', 'gaa', 'ae', 'ay', 'zaa', 'ba', 'aas', 'ava', 'aba', 'oa', 'aan', 'aam', 'ra', 'ag', 'an', 'aqa', 'az', 'apa', 'axa', 'xa', 'au', 'as', 'maa', 'ga', 'at', 'ja', 'aat'}\n",
      "pa\n",
      "{'na', 'pav', 'paf', 'npa', 'ja', 'py', 'za', 'pax', 'ya', 'opa', 'dpa', 'pba', 'pd', 'pp', 'ipa', 'ca', 'p', 'pla', 'pak', 'gpa', 'pae', 'epa', 'xpa', 'ka', 'ea', 'pka', 'psa', 'aa', 'pab', 'ph', 'pca', 'pm', 'kpa', 'par', 'pfa', 'jpa', 'sa', 'pu', 'mpa', 'pg', 'pai', 'pw', 'pj', 'pb', 'pe', 'zpa', 'pal', 'spa', 'po', 'pra', 'pma', 'pah', 'wpa', 'paw', 'pau', 'pk', 'pi', 'ps', 'pay', 'pwa', 'la', 'qpa', 'paj', 'pqa', 'pao', 'pya', 'ma', 'ia', 'qa', 'pva', 'paz', 'pda', 'pv', 'da', 'fa', 'pas', 'pea', 'ua', 'pha', 'poa', 'pza', 'pan', 'paa', 'pia', 'pz', 'pna', 'pga', 'paq', 'pn', 'hpa', 'tpa', 'pad', 'cpa', 'ypa', 'pua', 'px', 'ppa', 'ta', 'pl', 'ap', 'pr', 'pam', 'bpa', 'upa', 'pt', 'ha', 'pc', 'fpa', 'pac', 'a', 'lpa', 'va', 'pxa', 'pat', 'wa', 'ba', 'pta', 'oa', 'ra', 'pja', 'pag', 'rpa', 'pq', 'apa', 'xa', 'vpa', 'pap', 'ga', 'pf'}\n",
      "g\n",
      "{'', 'hg', 'z', 'q', 'o', 'v', 'gn', 'ig', 'c', 'n', 'gg', 'gs', 'og', 'lg', 'gh', 'xg', 'sg', 'wg', 'y', 'p', 'f', 'zg', 'gf', 'b', 'm', 'gv', 'gc', 'gl', 'tg', 'k', 'dg', 'go', 's', 'mg', 'gy', 'w', 'eg', 'ge', 'yg', 'qg', 't', 'pg', 'gp', 'ng', 'a', 'gk', 'gd', 'd', 'gw', 'i', 'gm', 'cg', 'vg', 'gx', 'gq', 'gz', 'fg', 'gt', 'r', 'l', 'gi', 'j', 'jg', 'ag', 'ug', 'e', 'gr', 'gu', 'rg', 'h', 'gb', 'u', 'kg', 'gj', 'ga', 'x', 'bg'}\n",
      "ao\n",
      "{'aom', 'co', 'amo', 'iao', 'o', 'aor', 'aon', 'aoi', 'yo', 'al', 'ak', 'fo', 'aa', 'aot', 'aou', 'vao', 'go', 'uo', 'aao', 'ab', 'ad', 'ko', 'eo', 'am', 'aov', 'aos', 'qao', 'bo', 'tao', 'so', 'auo', 'alo', 'aog', 'po', 'eao', 'io', 'oao', 'rao', 'ax', 'yao', 'qo', 'aok', 'gao', 'wo', 'oo', 'axo', 'ar', 'aoz', 'dao', 'aol', 'hao', 'ai', 'aop', 'zao', 'sao', 'aqo', 'pao', 'kao', 'lo', 'aq', 'aso', 'jo', 'to', 'aoh', 'awo', 'aod', 'fao', 'av', 'mo', 'abo', 'aoq', 'lao', 'aro', 'uao', 'no', 'ado', 'af', 'do', 'xo', 'avo', 'cao', 'azo', 'ac', 'aoa', 'aoy', 'ro', 'aco', 'aof', 'aoj', 'aj', 'aoo', 'aoc', 'ho', 'ajo', 'vo', 'ap', 'aeo', 'aho', 'apo', 'aio', 'aw', 'aoe', 'wao', 'a', 'afo', 'ah', 'ayo', 'ato', 'aob', 'ae', 'ay', 'ano', 'ago', 'oa', 'ako', 'zo', 'nao', 'ag', 'xao', 'an', 'mao', 'az', 'aow', 'au', 'as', 'aox', 'jao', 'at', 'bao'}\n",
      "s\n",
      "{'', 'ws', 'ss', 'sh', 'sy', 'z', 'vs', 'q', 'o', 'v', 'sb', 'ds', 'sk', 'sn', 'c', 'n', 'gs', 'ns', 'sr', 'sl', 'rs', 'sg', 'y', 'p', 'f', 'b', 'sm', 'm', 'ys', 'ks', 'sp', 'k', 'g', 'is', 'sv', 'w', 'sa', 'xs', 'sz', 'se', 'es', 't', 'fs', 'zs', 'si', 'sc', 'sf', 'a', 'sd', 'd', 'so', 'st', 'sw', 'i', 'sx', 'us', 'su', 'cs', 'js', 'r', 'os', 'l', 'j', 'ps', 'e', 'sj', 'ts', 'qs', 'hs', 'h', 'ls', 'u', 'ms', 'as', 'sq', 'x', 'bs'}\n",
      "aj\n",
      "{'qaj', 'ajb', 'uj', 'aqj', 'kj', 'ajd', 'vaj', 'vj', 'ajg', 'ajx', 'jj', 'aji', 'ajj', 'ayj', 'haj', 'abj', 'al', 'saj', 'caj', 'oaj', 'aja', 'ak', 'ajm', 'aa', 'ajt', 'dj', 'ahj', 'ajy', 'ab', 'mj', 'faj', 'aej', 'ad', 'asj', 'raj', 'acj', 'am', 'arj', 'aaj', 'pj', 'bj', 'axj', 'avj', 'laj', 'nj', 'iaj', 'rj', 'jaj', 'aij', 'ax', 'ar', 'afj', 'ajc', 'yaj', 'eaj', 'taj', 'akj', 'ai', 'ajq', 'atj', 'ajv', 'kaj', 'paj', 'ajl', 'ij', 'fj', 'yj', 'ajp', 'aq', 'amj', 'hj', 'ajz', 'ajf', 'gaj', 'tj', 'av', 'maj', 'af', 'zaj', 'adj', 'qj', 'zj', 'uaj', 'ac', 'agj', 'xaj', 'ao', 'oj', 'waj', 'apj', 'cj', 'alj', 'aoj', 'ajw', 'ajo', 'ap', 'awj', 'ej', 'ajk', 'aw', 'aje', 'azj', 'ajr', 'a', 'anj', 'ah', 'ajn', 'naj', 'lj', 'ae', 'ay', 'daj', 'ajh', 'aju', 'j', 'ag', 'an', 'az', 'sj', 'xj', 'wj', 'ajs', 'auj', 'au', 'baj', 'as', 'gj', 'at', 'ja'}\n",
      "w\n",
      "{'', 'ws', 'z', 'q', 'o', 'v', 'iw', 'c', 'n', 'yw', 'wf', 'wg', 'y', 'wr', 'p', 'f', 'wm', 'b', 'cw', 'uw', 'm', 'hw', 'fw', 'k', 'wc', 'wz', 'qw', 'g', 'jw', 'mw', 'tw', 's', 'wp', 'wn', 'wd', 'ew', 'vw', 'wi', 't', 'aw', 'wb', 'wl', 'pw', 'rw', 'a', 'wv', 'd', 'wt', 'gw', 'sw', 'i', 'wk', 'wh', 'lw', 'dw', 'wa', 'bw', 'wo', 'wu', 'r', 'l', 'j', 'ww', 'e', 'wq', 'wj', 'nw', 'h', 'zw', 'u', 'wx', 'we', 'kw', 'x', 'ow', 'wy', 'xw'}\n",
      "ta\n",
      "{'td', 'na', 'yta', 'tam', 'tsa', 'taa', 'za', 'tja', 'ya', 'zta', 'ca', 'tza', 'xta', 'tad', 'ka', 'ea', 'sta', 'taw', 'aa', 'taf', 'tfa', 'tba', 'ty', 'ita', 'tua', 'qta', 'sa', 'tan', 'rta', 't', 'tax', 'dta', 'tna', 'tya', 'tra', 'tp', 'tao', 'lta', 'tai', 'tq', 'tta', 'tma', 'tn', 'tqa', 'tah', 'taq', 'tb', 'tka', 'wta', 'tm', 'ota', 'tz', 'tv', 'tal', 'taj', 'tat', 'tae', 'la', 'tt', 'cta', 'tf', 'ma', 'tla', 'ia', 'qa', 'to', 'tl', 'tac', 'tga', 'da', 'tau', 'fa', 'tj', 'uta', 'tda', 'ua', 'tag', 'gta', 'te', 'tg', 'tas', 'pa', 'tpa', 'tc', 'txa', 'tw', 'taz', 'hta', 'ata', 'tia', 'tk', 'tr', 'jta', 'tab', 'bta', 'ha', 'th', 'tea', 'a', 'tu', 'va', 'kta', 'tav', 'tar', 'tak', 'ti', 'wa', 'fta', 'ba', 'pta', 'oa', 'tx', 'toa', 'tap', 'tha', 'ra', 'tca', 'mta', 'ts', 'tva', 'xa', 'tay', 'nta', 'twa', 'ga', 'vta', 'eta', 'at', 'ja'}\n",
      "sa\n",
      "{'na', 'sh', 'sy', 'tsa', 'saw', 'za', 'sl', 'ya', 'sg', 'usa', 'ca', 'sga', 'saj', 'ka', 'ea', 'psa', 'sia', 'sta', 'aa', 'dsa', 'sva', 'sca', 'xsa', 'sav', 'sak', 'sua', 'sz', 'se', 'msa', 'sza', 'vsa', 'san', 'esa', 'sd', 'so', 'sap', 'sax', 'sx', 'sda', 'sja', 'spa', 'su', 'ysa', 'sxa', 'zsa', 'sau', 'osa', 'la', 'sao', 'sai', 'ksa', 'csa', 'ma', 'sae', 'sam', 'ss', 'ia', 'qa', 'sac', 'qsa', 'jsa', 'sb', 'sn', 'sk', 'da', 'rsa', 'fa', 'sr', 'sal', 'saq', 'sad', 'sma', 'saa', 'ua', 'sm', 'sas', 'sna', 'sat', 'hsa', 'sqa', 'sp', 'sea', 'pa', 'sah', 'sab', 'bsa', 's', 'sv', 'ta', 'asa', 'si', 'ska', 'sc', 'sf', 'ha', 'swa', 'sya', 'a', 'va', 'st', 'fsa', 'sw', 'sfa', 'wa', 'sba', 'wsa', 'ba', 'ssa', 'lsa', 'nsa', 'sar', 'oa', 'sla', 'ra', 'sha', 'soa', 'sj', 'sag', 'saf', 'saz', 'gsa', 'xa', 'isa', 'as', 'sq', 'ga', 'sra', 'ja', 'say'}\n",
      "ap\n",
      "{'nap', 'app', 'rap', 'apx', 'apy', 'apz', 'api', 'xap', 'eap', 'apg', 'apt', 'oap', 'pp', 'lp', 'gap', 'ahp', 'p', 'aph', 'al', 'aap', 'ip', 'ak', 'apr', 'adp', 'aa', 'kap', 'fap', 'aqp', 'ab', 'ad', 'aup', 'am', 'gp', 'zp', 'jp', 'fp', 'tp', 'hp', 'ep', 'apn', 'aip', 'akp', 'sap', 'atp', 'qp', 'ayp', 'bp', 'up', 'ax', 'cp', 'jap', 'ar', 'apu', 'alp', 'ape', 'anp', 'ai', 'op', 'yp', 'aop', 'azp', 'dap', 'apb', 'apd', 'apm', 'ajp', 'zap', 'aq', 'vap', 'arp', 'uap', 'abp', 'av', 'vp', 'apk', 'aps', 'xp', 'af', 'apf', 'acp', 'ac', 'sp', 'wap', 'pa', 'ao', 'agp', 'amp', 'apj', 'wp', 'aj', 'bap', 'awp', 'apw', 'apo', 'axp', 'aw', 'afp', 'mp', 'a', 'apc', 'ah', 'iap', 'apv', 'kp', 'ae', 'ay', 'map', 'aep', 'lap', 'avp', 'rp', 'qap', 'tap', 'hap', 'apq', 'apl', 'ag', 'an', 'az', 'asp', 'apa', 'yap', 'pap', 'np', 'au', 'as', 'dp', 'at', 'cap'}\n",
      "ab\n",
      "{'alb', 'ajb', 'wab', 'zab', 'bb', 'aeb', 'abf', 'aby', 'b', 'abj', 'al', 'eab', 'ak', 'azb', 'ob', 'aa', 'cb', 'qb', 'zb', 'fab', 'kab', 'pab', 'atb', 'afb', 'ib', 'yab', 'abx', 'abg', 'abq', 'vb', 'amb', 'ad', 'nb', 'abn', 'am', 'aab', 'aib', 'abh', 'hab', 'pb', 'anb', 'vab', 'agb', 'fb', 'avb', 'abr', 'nab', 'rb', 'cab', 'ax', 'tb', 'ar', 'abw', 'ai', 'abk', 'apb', 'gb', 'aq', 'gab', 'dab', 'sb', 'iab', 'akb', 'lab', 'abb', 'abp', 'abc', 'av', 'abd', 'abo', 'jab', 'axb', 'arb', 'jb', 'db', 'af', 'abe', 'ac', 'abv', 'sab', 'ao', 'aj', 'aub', 'oab', 'xab', 'abz', 'uab', 'ap', 'yb', 'tab', 'aw', 'ub', 'qab', 'wb', 'acb', 'a', 'rab', 'abi', 'ah', 'lb', 'adb', 'ahb', 'aob', 'asb', 'abt', 'kb', 'mb', 'ae', 'ay', 'aqb', 'ba', 'aba', 'abu', 'bab', 'abm', 'ag', 'mab', 'eb', 'awb', 'an', 'xb', 'az', 'abl', 'ayb', 'au', 'abs', 'as', 'at', 'hb'}\n",
      "t\n",
      "{'', 'td', 'ot', 'z', 'vt', 'q', 'to', 'o', 'v', 'tl', 'c', 'n', 'mt', 'tj', 'xt', 'y', 'zt', 'p', 'f', 'yt', 'b', 'm', 'ut', 'te', 'tg', 'k', 'g', 'ft', 'tc', 'tw', 's', 'ty', 'bt', 'w', 'ta', 'tk', 'tr', 'it', 'pt', 'tp', 'th', 'rt', 'ct', 'a', 'lt', 'tu', 'kt', 'd', 'wt', 'st', 'qt', 'i', 'ti', 'tq', 'tn', 'tb', 'tm', 'tx', 'gt', 'tz', 'r', 'tv', 'l', 'et', 'j', 'jt', 'e', 'ts', 'tt', 'ht', 'h', 'u', 'dt', 'nt', 'tf', 'x', 'at'}\n",
      "aw\n",
      "{'yw', 'saw', 'oaw', 'gaw', 'asw', 'acw', 'awk', 'awn', 'awq', 'al', 'ak', 'taw', 'fw', 'aa', 'qw', 'jw', 'mw', 'awl', 'awy', 'ab', 'aww', 'ad', 'am', 'aew', 'pw', 'awd', 'aqw', 'gw', 'awv', 'lw', 'ayw', 'anw', 'atw', 'awt', 'ax', 'paw', 'ar', 'daw', 'awe', 'awr', 'aws', 'abw', 'ai', 'nw', 'alw', 'akw', 'maw', 'avw', 'ow', 'ahw', 'adw', 'aq', 'iaw', 'yaw', 'awc', 'iw', 'axw', 'awo', 'haw', 'av', 'raw', 'awa', 'agw', 'awh', 'azw', 'law', 'cw', 'uw', 'af', 'faw', 'hw', 'ac', 'awx', 'ao', 'tw', 'eaw', 'awg', 'waw', 'aj', 'w', 'jaw', 'awi', 'ew', 'vw', 'ajw', 'apw', 'awp', 'ap', 'awj', 'kaw', 'baw', 'rw', 'a', 'auw', 'ah', 'caw', 'aaw', 'sw', 'dw', 'wa', 'xaw', 'afw', 'amw', 'ae', 'ay', 'bw', 'awz', 'qaw', 'ag', 'ww', 'awb', 'an', 'aow', 'az', 'zaw', 'awf', 'arw', 'aiw', 'au', 'zw', 'awm', 'as', 'vaw', 'awu', 'kw', 'naw', 'uaw', 'at', 'xw'}\n",
      "ad\n",
      "{'td', 'hd', 'dad', 'ead', 'vd', 'aad', 'aed', 'ajd', 'atd', 'md', 'pd', 'bd', 'wad', 'adf', 'qd', 'al', 'tad', 'ak', 'adp', 'aa', 'ed', 'acd', 'fd', 'gad', 'adk', 'nd', 'dd', 'ab', 'xad', 'fad', 'am', 'afd', 'awd', 'sd', 'gd', 'od', 'ard', 'kd', 'rad', 'aid', 'ayd', 'xd', 'akd', 'ax', 'adv', 'qad', 'axd', 'adz', 'ar', 'iad', 'ada', 'id', 'amd', 'adt', 'ai', 'ahd', 'adm', 'adh', 'bad', 'apd', 'cd', 'adw', 'aq', 'zad', 'da', 'aod', 'adx', 'av', 'sad', 'abd', 'lad', 'kad', 'ado', 'adl', 'af', 'adj', 'nad', 'avd', 'ac', 'and', 'ud', 'adq', 'pad', 'ao', 'cad', 'azd', 'aj', 'had', 'ads', 'wd', 'mad', 'adg', 'ap', 'jad', 'ld', 'aud', 'rd', 'adn', 'aw', 'adi', 'a', 'ah', 'd', 'ade', 'yad', 'adu', 'adb', 'asd', 'jd', 'uad', 'ae', 'ay', 'oad', 'aqd', 'zd', 'agd', 'ald', 'ady', 'ag', 'an', 'az', 'adc', 'adr', 'add', 'yd', 'au', 'as', 'at', 'vad'}\n",
      "am\n",
      "{'aom', 'ahm', 'ams', 'afm', 'amo', 'mm', 'mam', 'tam', 'aum', 'alm', 'oam', 'km', 'ami', 'wm', 'hm', 'jm', 'm', 'akm', 'al', 'amt', 'yam', 'qam', 'wam', 'ak', 'jam', 'qm', 'ajm', 'aa', 'avm', 'aem', 'pm', 'uam', 'bm', 'axm', 'ame', 'ab', 'amb', 'amm', 'ad', 'asm', 'ym', 'vam', 'zam', 'ram', 'im', 'aml', 'ax', 'dam', 'aym', 'tm', 'zm', 'ar', 'amd', 'fam', 'ai', 'adm', 'dm', 'amn', 'ma', 'kam', 'sam', 'apm', 'lm', 'aq', 'aqm', 'vm', 'gam', 'amj', 'amu', 'om', 'av', 'em', 'lam', 'amz', 'sm', 'af', 'cm', 'agm', 'amc', 'ac', 'atm', 'ham', 'acm', 'ao', 'amp', 'anm', 'ama', 'aj', 'azm', 'amr', 'pam', 'ap', 'aw', 'nm', 'amk', 'nam', 'cam', 'amh', 'a', 'ah', 'arm', 'xam', 'fm', 'amy', 'gm', 'um', 'ae', 'ay', 'amw', 'amx', 'bam', 'aam', 'abm', 'amq', 'ag', 'an', 'az', 'amg', 'aim', 'eam', 'amf', 'rm', 'au', 'awm', 'xm', 'as', 'iam', 'at', 'amv'}\n",
      "ha\n",
      "{'hd', 'yha', 'na', 'hay', 'hal', 'hn', 'za', 'hwa', 'ya', 'hv', 'hz', 'ca', 'hra', 'hm', 'haj', 'has', 'hy', 'hat', 'ka', 'ea', 'aa', 'he', 'zha', 'xha', 'han', 'mha', 'sa', 'qha', 'haq', 'hka', 'iha', 'hag', 'lha', 'hoa', 'hab', 'hp', 'eha', 'aha', 'hua', 'jha', 'hha', 'haz', 'hr', 'hq', 'hu', 'hah', 'hao', 'hh', 'hak', 'uha', 'hja', 'la', 'ht', 'gha', 'hl', 'hs', 'h', 'hca', 'ma', 'hla', 'hg', 'ia', 'qa', 'kha', 'hfa', 'hj', 'hxa', 'da', 'haw', 'vha', 'fa', 'hai', 'hia', 'hav', 'ua', 'pha', 'hw', 'hk', 'hsa', 'hqa', 'fha', 'hna', 'cha', 'pa', 'hpa', 'ham', 'wha', 'hta', 'had', 'ta', 'ho', 'haa', 'hau', 'a', 'va', 'ah', 'hda', 'hi', 'hc', 'oha', 'wa', 'bha', 'hac', 'ba', 'hax', 'rha', 'nha', 'haf', 'oa', 'hap', 'tha', 'hea', 'hf', 'ra', 'dha', 'sha', 'hga', 'hva', 'hx', 'xa', 'hya', 'hza', 'hba', 'hae', 'ga', 'hma', 'har', 'ja', 'hb'}\n",
      "va\n",
      "{'na', 'vza', 'uva', 'vd', 'vva', 'vah', 'vi', 'za', 'vaj', 'vaq', 'kva', 'vj', 'ya', 'vai', 'vua', 'vv', 'vwa', 'ca', 've', 'nva', 'vya', 'ka', 'ea', 'aa', 'val', 'vao', 'vax', 'var', 'sva', 'vak', 'vka', 'vga', 'vae', 'sa', 'yva', 'vb', 'vna', 'vsa', 'wva', 'vam', 'vc', 'dva', 'vab', 'vaz', 'bva', 'xva', 'vag', 'cva', 'vqa', 'vla', 'vu', 'vau', 'vh', 'vx', 'la', 'ma', 'vas', 'ia', 'qa', 'vt', 'vm', 'pva', 'vfa', 'vs', 'vac', 'vap', 'zva', 'v', 'vq', 'vea', 'da', 'mva', 'vha', 'fa', 'vf', 'av', 'vra', 'eva', 'vp', 'voa', 'vba', 'ua', 'vma', 'vca', 'vda', 'via', 'pa', 'vaa', 'vk', 'jva', 'vja', 'vat', 'ta', 'ova', 'vw', 'vz', 'vo', 'gva', 'vay', 'vxa', 'vl', 'ha', 'vy', 'fva', 'a', 'van', 'qva', 'wa', 'vg', 'iva', 'ba', 'ava', 'rva', 'oa', 'vr', 'vn', 'ra', 'hva', 'tva', 'xa', 'vpa', 'vaf', 'lva', 'vav', 'vaw', 'ga', 'vta', 'ja', 'vad'}\n",
      "ah\n",
      "{'ahm', 'sh', 'axh', 'ahu', 'uh', 'ahk', 'bah', 'vah', 'gah', 'ahg', 'ahs', 'ahp', 'kh', 'aph', 'ahl', 'al', 'aqh', 'avh', 'ak', 'aa', 'ahf', 'ph', 'dah', 'uah', 'ahj', 'ahr', 'jah', 'ab', 'ash', 'jh', 'ad', 'fh', 'yah', 'am', 'abh', 'aha', 'nah', 'eah', 'nh', 'ayh', 'aah', 'pah', 'tah', 'ax', 'alh', 'aht', 'ahy', 'iah', 'ar', 'vh', 'ahc', 'hah', 'qah', 'hh', 'ai', 'aih', 'ahx', 'ahd', 'h', 'adh', 'ahv', 'ahw', 'ahe', 'aq', 'cah', 'rah', 'aoh', 'gh', 'kah', 'av', 'ahi', 'ahq', 'oah', 'ih', 'lah', 'awh', 'qh', 'af', 'ac', 'azh', 'auh', 'ch', 'sah', 'xah', 'ao', 'rh', 'fah', 'wah', 'aeh', 'aj', 'eh', 'ath', 'zh', 'zah', 'ap', 'aho', 'ahz', 'aw', 'mh', 'xh', 'bh', 'ach', 'ahn', 'ha', 'th', 'afh', 'amh', 'a', 'arh', 'ahh', 'ahb', 'mah', 'wh', 'yh', 'ae', 'ay', 'akh', 'anh', 'agh', 'ajh', 'ag', 'an', 'az', 'dh', 'au', 'as', 'oh', 'at', 'lh'}\n",
      "d\n",
      "{'', 'hd', 'td', 'z', 'q', 'o', 'v', 'ds', 'vd', 'c', 'n', 'da', 'dq', 'md', 'dv', 'pd', 'bd', 'y', 'dy', 'p', 'f', 'b', 'db', 'm', 'qd', 'dn', 'do', 'de', 'k', 'ed', 'ud', 'g', 'dj', 'dg', 'fd', 's', 'dz', 'di', 'dr', 'nd', 'w', 'wd', 'dd', 'dc', 'dk', 't', 'ld', 'rd', 'ad', 'a', 'sd', 'gd', 'od', 'kd', 'i', 'jd', 'dw', 'dl', 'xd', 'zd', 'dx', 'df', 'r', 'l', 'id', 'j', 'e', 'yd', 'dh', 'h', 'u', 'dm', 'dt', 'dp', 'x', 'du', 'cd'}\n",
      "i\n",
      "{'', 'iq', 'ri', 'qi', 'z', 'ia', 'q', 'o', 'v', 'iw', 'ig', 'c', 'n', 'vi', 'in', 'li', 'il', 'ih', 'oi', 'y', 'p', 'f', 'iy', 'ui', 'b', 'm', 'ik', 'ip', 'k', 'g', 'ni', 's', 'ib', 'if', 'iz', 'is', 'di', 'w', 'ii', 'wi', 'iv', 't', 'iu', 'it', 'si', 'ix', 'fi', 'a', 'd', 'hi', 'ti', 'xi', 'zi', 'im', 'ei', 'io', 'ie', 'bi', 'ci', 'r', 'l', 'ki', 'gi', 'id', 'j', 'pi', 'ir', 'e', 'ai', 'ic', 'h', 'u', 'ji', 'x', 'mi', 'ij', 'yi'}\n",
      "wa\n",
      "{'nwa', 'na', 'uwa', 'wab', 'bwa', 'za', 'lwa', 'hwa', 'wea', 'wag', 'ya', 'vwa', 'wad', 'ca', 'wm', 'woa', 'war', 'wam', 'ka', 'ea', 'wfa', 'aa', 'wc', 'way', 'wan', 'waf', 'waa', 'qwa', 'dwa', 'sa', 'wra', 'wza', 'wi', 'fwa', 'wak', 'wl', 'wva', 'wka', 'wt', 'wwa', 'wai', 'wja', 'wk', 'wau', 'iwa', 'wua', 'kwa', 'wta', 'wo', 'wu', 'wpa', 'ewa', 'zwa', 'wax', 'wq', 'wae', 'pwa', 'la', 'mwa', 'wx', 'ma', 'was', 'xwa', 'wy', 'ywa', 'ws', 'owa', 'ia', 'qa', 'wxa', 'da', 'gwa', 'fa', 'wf', 'awa', 'wg', 'wr', 'ua', 'wna', 'wqa', 'wla', 'wap', 'pa', 'wz', 'jwa', 'wha', 'waz', 'waj', 'wah', 'wp', 'wn', 'waw', 'w', 'ta', 'wd', 'wma', 'aw', 'wb', 'ha', 'swa', 'wat', 'wao', 'a', 'va', 'wv', 'wba', 'wh', 'wya', 'cwa', 'wsa', 'ba', 'rwa', 'wga', 'wav', 'oa', 'wia', 'ra', 'ww', 'wac', 'wj', 'wal', 'xa', 'twa', 'wda', 'we', 'ga', 'waq', 'ja', 'wca'}\n",
      "ae\n",
      "{'eae', 'age', 'be', 'aed', 'nae', 'aeb', 'afe', 'aef', 'mae', 've', 'ee', 'dae', 'ke', 'al', 'pae', 'aye', 'ze', 'ael', 'ea', 'ak', 'je', 'ue', 'aa', 'he', 'aem', 'oe', 'vae', 'gae', 'aei', 'ame', 'se', 'ab', 'aej', 'ad', 'me', 'am', 'aew', 'pe', 'at', 'kae', 'ale', 'aen', 'ie', 'ax', 'aee', 'aae', 'ar', 'xe', 'aec', 'awe', 'ape', 'e', 'ai', 'wae', 'xae', 'tae', 'cae', 'ane', 'bae', 'ase', 'iae', 'aev', 'aex', 'ne', 'aes', 'sae', 'jae', 'ahe', 'aq', 'aea', 'ye', 'ake', 'aie', 'av', 'ate', 'aey', 'are', 'aer', 'af', 'ace', 'abe', 'te', 'ac', 'aeu', 'de', 'aeq', 'aez', 'fae', 'ao', 'aeh', 'rae', 'aj', 'axe', 'ge', 'aeo', 'ap', 'aw', 'aje', 'aoe', 'aek', 'uae', 'a', 'ah', 'qae', 'ade', 'qe', 'oae', 'le', 'ay', 'zae', 'aep', 'aue', 'aqe', 'yae', 'ave', 're', 'ce', 'ag', 'an', 'aze', 'az', 'lae', 'au', 'as', 'hae', 'we', 'aeg', 'aet', 'fe'}\n",
      "ay\n",
      "{'qy', 'hay', 'sy', 'oay', 'acy', 'apy', 'ey', 'py', 'bay', 'day', 'ya', 'lay', 'aly', 'uy', 'zy', 'aby', 'ayj', 'yy', 'ayq', 'hy', 'al', 'aye', 'ak', 'jay', 'aa', 'way', 'zay', 'jy', 'awy', 'ty', 'gy', 'ajy', 'ab', 'may', 'fy', 'ayz', 'ad', 'fay', 'am', 'ays', 'ly', 'ry', 'ayd', 'ayp', 'ayw', 'afy', 'ayh', 'ax', 'aym', 'ahy', 'xy', 'uay', 'ar', 'ayl', 'aqy', 'axy', 'azy', 'ai', 'ary', 'aky', 'pay', 'ayy', 'ayv', 'wy', 'yay', 'aq', 'av', 'xay', 'ayg', 'aey', 'aya', 'y', 'dy', 'iy', 'eay', 'cay', 'af', 'iay', 'cy', 'ac', 'aoy', 'ayc', 'ao', 'gay', 'ny', 'aj', 'asy', 'aty', 'ayf', 'kay', 'ap', 'vay', 'aay', 'aw', 'ayu', 'vy', 'a', 'oy', 'ah', 'ayo', 'qay', 'agy', 'ray', 'amy', 'any', 'ae', 'ayk', 'ayr', 'aiy', 'auy', 'by', 'nay', 'ady', 'ag', 'an', 'az', 'my', 'ayn', 'ayt', 'tay', 'ayb', 'au', 'avy', 'ky', 'ayi', 'as', 'ayx', 'at', 'say'}\n",
      "ba\n",
      "{'na', 'iba', 'bwa', 'be', 'baf', 'bv', 'bah', 'bb', 'bia', 'za', 'bay', 'ya', 'pba', 'bya', 'bd', 'ca', 'b', 'rba', 'bza', 'ka', 'ea', 'bc', 'aa', 'lba', 'bac', 'oba', 'tba', 'sa', 'bm', 'ab', 'bat', 'gba', 'bj', 'bo', 'baz', 'bna', 'bva', 'eba', 'bda', 'bma', 'bga', 'bp', 'bea', 'bal', 'bi', 'bxa', 'bav', 'bao', 'la', 'bae', 'br', 'qba', 'bad', 'bg', 'ma', 'cba', 'bba', 'ia', 'qa', 'bas', 'bai', 'bja', 'bak', 'da', 'fa', 'baa', 'vba', 'xba', 'baq', 'ua', 'bf', 'ban', 'bua', 'jba', 'pa', 'bsa', 'boa', 'dba', 'bq', 'bt', 'bap', 'bl', 'bx', 'ta', 'bau', 'zba', 'bpa', 'bn', 'bh', 'bta', 'ha', 'kba', 'baw', 'a', 'bqa', 'bax', 'va', 'bra', 'wba', 'yba', 'mba', 'bag', 'bka', 'wa', 'sba', 'bha', 'bw', 'bca', 'nba', 'aba', 'bam', 'oa', 'bk', 'by', 'bla', 'bab', 'ra', 'bfa', 'uba', 'bar', 'xa', 'bz', 'baj', 'fba', 'hba', 'ga', 'ja', 'bs', 'bu'}\n",
      "ax\n",
      "{'axh', 'yax', 'apx', 'axv', 'axq', 'oax', 'cx', 'jx', 'pax', 'gax', 'ajx', 'max', 'zax', 'akx', 'al', 'xx', 'axc', 'ak', 'mx', 'aa', 'iax', 'vax', 'axn', 'ex', 'ox', 'axf', 'alx', 'aax', 'qax', 'abx', 'rax', 'axg', 'axm', 'ab', 'axz', 'atx', 'tax', 'ad', 'am', 'axj', 'axu', 'sax', 'sx', 'kax', 'uax', 'ayx', 'dx', 'axd', 'agx', 'axo', 'ar', 'axx', 'wax', 'axy', 'eax', 'lx', 'ai', 'vx', 'kx', 'ahx', 'acx', 'axr', 'nx', 'aex', 'wx', 'x', 'aq', 'xax', 'axw', 'nax', 'adx', 'av', 'axb', 'dax', 'yx', 'axi', 'af', 'zx', 'azx', 'ac', 'cax', 'awx', 'ao', 'jax', 'aux', 'asx', 'qx', 'axl', 'aj', 'px', 'axe', 'bx', 'axk', 'fax', 'axs', 'axt', 'ap', 'axp', 'aw', 'ix', 'lax', 'a', 'bax', 'aix', 'ah', 'afx', 'anx', 'gx', 'ae', 'ay', 'hax', 'amx', 'ux', 'tx', 'ag', 'an', 'aqx', 'az', 'axa', 'hx', 'xa', 'au', 'avx', 'fx', 'as', 'arx', 'rx', 'aox', 'at'}\n",
      "oa\n",
      "{'na', 'ot', 'ora', 'oay', 'o', 'oak', 'ja', 'oax', 'og', 'za', 'oaw', 'oam', 'oap', 'roa', 'ya', 'oja', 'opa', 'oi', 'ca', 'woa', 'oq', 'foa', 'oaj', 'ka', 'ea', 'moa', 'ob', 'aa', 'oai', 'goa', 'oba', 'ox', 'oe', 'oar', 'oau', 'oas', 'sa', 'on', 'hoa', 'ofa', 'od', 'doa', 'oav', 'uoa', 'ola', 'oao', 'oat', 'ota', 'oo', 'joa', 'oaa', 'oal', 'oda', 'oxa', 'oea', 'osa', 'ok', 'oan', 'op', 'la', 'oca', 'oua', 'ow', 'ma', 'owa', 'ia', 'qa', 'ol', 'oc', 'da', 'noa', 'oac', 'fa', 'om', 'voa', 'oah', 'of', 'oaf', 'ua', 'poa', 'ooa', 'yoa', 'pa', 'oga', 'aoa', 'ao', 'ioa', 'boa', 'ou', 'oqa', 'oj', 'zoa', 'ta', 'oab', 'ova', 'or', 'oza', 'ha', 'koa', 'oia', 'ona', 'a', 'va', 'oz', 'oy', 'oya', 'loa', 'oae', 'oag', 'qoa', 'oaq', 'oka', 'oha', 'wa', 'ov', 'oad', 'ba', 'oma', 'toa', 'os', 'ra', 'xoa', 'soa', 'coa', 'xa', 'oaz', 'ga', 'oh', 'eoa'}\n",
      "r\n",
      "{'', 'ri', 'z', 'ru', 'lr', 'q', 'o', 'zr', 'v', 'c', 'n', 'rk', 'nr', 'sr', 'rs', 'er', 'ur', 'y', 'wr', 'p', 'f', 'jr', 'b', 'rr', 'm', 'rl', 'k', 'g', 'fr', 'rv', 'rh', 'rc', 's', 'ro', 'kr', 'w', 'dr', 'rq', 'xr', 'pr', 't', 'tr', 'rd', 'or', 'mr', 'rt', 'rw', 'a', 'cr', 'qr', 'ry', 'd', 'i', 'rb', 'rj', 'rp', 'yr', 'vr', 're', 'ar', 'l', 'ra', 'rz', 'j', 'hr', 'ir', 'e', 'gr', 'rn', 'rg', 'rf', 'rm', 'h', 'br', 'u', 'x', 'rx'}\n",
      "ar\n",
      "{'mar', 'aar', 'lr', 'zr', 'art', 'rar', 'aor', 'ear', 'akr', 'dar', 'jar', 'er', 'xar', 'jr', 'war', 'zar', 'al', 'aru', 'ak', 'apr', 'aa', 'fr', 'var', 'gar', 'oar', 'par', 'dr', 'ahr', 'xr', 'ab', 'ad', 'am', 'arj', 'agr', 'cr', 'ard', 'avr', 'air', 'arz', 'alr', 'arq', 'abr', 'arl', 'ax', 'atr', 'yr', 'yar', 'afr', 'awr', 'hr', 'ai', 'ary', 'ars', 'axr', 'br', 'anr', 'iar', 'acr', 'arv', 'aq', 'arg', 'car', 'ark', 'arr', 'arp', 'nr', 'sr', 'aqr', 'av', 'are', 'ur', 'aro', 'arb', 'wr', 'aer', 'ara', 'rr', 'af', 'arn', 'ac', 'arc', 'asr', 'qar', 'ao', 'far', 'aj', 'kr', 'amr', 'pr', 'ap', 'tr', 'or', 'aw', 'mr', 'nar', 'ari', 'ajr', 'a', 'arh', 'qr', 'ah', 'arm', 'tar', 'ae', 'ay', 'lar', 'azr', 'ayr', 'sar', 'vr', 'arf', 'r', 'ra', 'ag', 'ir', 'an', 'gr', 'az', 'bar', 'adr', 'aur', 'kar', 'arw', 'au', 'as', 'har', 'arx', 'at', 'uar'}\n",
      "l\n",
      "{'', 'lo', 'z', 'ol', 'lr', 'll', 'q', 'o', 'v', 'kl', 'tl', 'c', 'n', 'lg', 'li', 'il', 'sl', 'y', 'lp', 'p', 'f', 'b', 'lz', 'm', 'al', 'gl', 'rl', 'k', 'g', 'ul', 's', 'cl', 'nl', 'w', 'bl', 'xl', 'pl', 't', 'yl', 'ld', 'lc', 'el', 'vl', 'wl', 'ly', 'a', 'lt', 'lb', 'd', 'le', 'lj', 'lq', 'lu', 'i', 'lv', 'lw', 'dl', 'lf', 'lk', 'r', 'ln', 'jl', 'fl', 'j', 'e', 'lx', 'ml', 'la', 'zl', 'hl', 'ls', 'h', 'u', 'ql', 'x', 'lh', 'lm'}\n",
      "ra\n",
      "{'na', 'ora', 'ri', 'xra', 'rap', 'rar', 'za', 'ral', 'roa', 'ya', 'rs', 'raf', 'ca', 'hra', 'ura', 'rba', 'gra', 'rl', 'ka', 'ea', 'aa', 'rq', 'sa', 'wra', 'yra', 'rax', 'rta', 'raj', 'tra', 'rza', 'rt', 'ram', 'rka', 'ry', 'raq', 'rxa', 'rav', 'rad', 'rma', 'ria', 'rb', 'rj', 'pra', 'rao', 'fra', 'qra', 'raa', 'ar', 'rda', 'ras', 'rra', 'rf', 'la', 'rau', 'ma', 'rqa', 'ia', 'qa', 'ru', 'rca', 'ran', 'rah', 'da', 'rk', 'rsa', 'fa', 'raw', 'vra', 'raz', 'ua', 'rla', 'ara', 'rr', 'rga', 'cra', 'jra', 'zra', 'lra', 'pa', 'rv', 'rh', 'rc', 'nra', 'rna', 'ro', 'kra', 'rae', 'rag', 'ta', 'rd', 'rat', 'rya', 'ha', 'rw', 'a', 'rab', 'va', 'bra', 'rja', 'rfa', 'rua', 'ray', 'wa', 'ba', 'rwa', 'rva', 'rha', 'rea', 'rai', 'rp', 'mra', 'oa', 'dra', 'r', 're', 'era', 'ira', 'rz', 'rpa', 'rn', 'rak', 'rg', 'xa', 'rm', 'ga', 'rx', 'rac', 'sra', 'ja'}\n",
      "j\n",
      "{'', 'yj', 'z', 'jo', 'q', 'uj', 'o', 'v', 'hj', 'kj', 'c', 'n', 'jn', 'jx', 'tj', 'vj', 'jj', 'y', 'p', 'f', 'jc', 'jr', 'b', 'jb', 'jm', 'jv', 'm', 'qj', 'jk', 'zj', 'je', 'k', 'g', 'dj', 'jw', 'jy', 's', 'oj', 'cj', 'aj', 'w', 't', 'ju', 'mj', 'ej', 'jh', 'jp', 'pj', 'a', 'bj', 'd', 'jz', 'lj', 'nj', 'i', 'jd', 'rj', 'js', 'r', 'l', 'jl', 'jg', 'jt', 'e', 'sj', 'xj', 'wj', 'jf', 'jq', 'h', 'u', 'ji', 'gj', 'x', 'ja', 'ij', 'fj'}\n",
      "ag\n",
      "{'dag', 'yag', 'age', 'ig', 'og', 'apg', 'ahg', 'wag', 'ajg', 'sg', 'agz', 'mag', 'avg', 'al', 'ak', 'aa', 'g', 'agn', 'ags', 'jag', 'acg', 'xag', 'abg', 'qg', 'atg', 'axg', 'ab', 'ad', 'hag', 'pg', 'am', 'aig', 'asg', 'agr', 'agq', 'agb', 'agt', 'vag', 'cg', 'aog', 'aga', 'agu', 'ax', 'agk', 'lag', 'fg', 'agx', 'ar', 'akg', 'jg', 'ai', 'zag', 'agf', 'agv', 'bg', 'hg', 'cag', 'aq', 'arg', 'azg', 'agc', 'agi', 'gg', 'lg', 'xg', 'av', 'ayg', 'wg', 'iag', 'agw', 'zg', 'tag', 'fag', 'af', 'agm', 'ac', 'tg', 'eag', 'agj', 'alg', 'gag', 'ao', 'dg', 'agp', 'qag', 'awg', 'mg', 'aj', 'rag', 'eg', 'ang', 'yg', 'adg', 'ap', 'aw', 'aug', 'ng', 'a', 'agl', 'aag', 'ah', 'aqg', 'oag', 'bag', 'agy', 'vg', 'ae', 'ay', 'agg', 'agd', 'ago', 'agh', 'nag', 'pag', 'ug', 'an', 'az', 'sag', 'amg', 'rg', 'kag', 'uag', 'au', 'as', 'kg', 'aeg', 'ga', 'afg', 'at'}\n",
      "an\n",
      "{'na', 'hn', 'gn', 'kn', 'anv', 'n', 'in', 'yan', 'jn', 'aon', 'cn', 'awn', 'al', 'ak', 'ank', 'aa', 'yn', 'wan', 'axn', 'can', 'agn', 'fan', 'han', 'anc', 'tan', 'on', 'ab', 'anq', 'ian', 'ad', 'en', 'abn', 'atn', 'am', 'san', 'xan', 'ean', 'apn', 'anb', 'anw', 'aen', 'tn', 'ax', 'lan', 'ar', 'zn', 'akn', 'anp', 'ai', 'oan', 'avn', 'ane', 'ans', 'uan', 'anr', 'amn', 'ana', 'man', 'aq', 'dan', 'ran', 'acn', 'nn', 'sn', 'ant', 'ani', 'av', 'qan', 'xn', 'afn', 'pan', 'aqn', 'ban', 'af', 'dn', 'arn', 'ac', 'and', 'pn', 'anl', 'ao', 'zan', 'anm', 'nan', 'wn', 'aj', 'aun', 'un', 'ang', 'ap', 'ann', 'adn', 'aw', 'bn', 'ain', 'fn', 'ahn', 'gan', 'a', 'van', 'anj', 'anz', 'ah', 'ajn', 'any', 'anu', 'anx', 'ae', 'ay', 'qn', 'kan', 'anh', 'ano', 'aan', 'ln', 'vn', 'jan', 'ag', 'asn', 'mn', 'az', 'rn', 'anf', 'ayn', 'au', 'aln', 'as', 'azn', 'at'}\n",
      "e\n",
      "{'', 'z', 'q', 'be', 'o', 'v', 'ye', 'c', 'n', 'ey', 'em', 'er', 'y', 'eu', 'p', 'f', 'ee', 've', 'b', 'm', 'ke', 'ze', 'te', 'ea', 'je', 'ue', 'de', 'k', 'he', 'ed', 'ek', 'g', 'ex', 's', 'oe', 'eh', 'w', 'eg', 'ge', 'ew', 'se', 'es', 't', 'ej', 'en', 'el', 'me', 'eo', 'ep', 'pe', 'a', 'd', 'qe', 'le', 'i', 'ev', 'eq', 'ei', 'ae', 'ie', 'ec', 'ez', 'r', 're', 'l', 'ef', 'xe', 'ce', 'et', 'j', 'eb', 'h', 'u', 'ne', 'we', 'x', 'fe'}\n",
      "az\n",
      "{'apz', 'aqz', 'za', 'hz', 'aza', 'agz', 'zz', 'alz', 'al', 'yz', 'azu', 'iaz', 'ak', 'azb', 'auz', 'aa', 'gaz', 'faz', 'dz', 'caz', 'sz', 'ab', 'axz', 'ayz', 'ad', 'afz', 'xz', 'am', 'qaz', 'asz', 'baz', 'arz', 'jz', 'vaz', 'azf', 'akz', 'gz', 'ax', 'laz', 'azc', 'tz', 'adz', 'haz', 'ar', 'aoz', 'qz', 'yaz', 'azy', 'ai', 'aaz', 'avz', 'eaz', 'azp', 'xaz', 'daz', 'atz', 'azt', 'aq', 'z', 'paz', 'azg', 'maz', 'ajz', 'acz', 'azs', 'av', 'cz', 'raz', 'amz', 'nz', 'azk', 'azw', 'lz', 'af', 'azo', 'pz', 'azx', 'azl', 'ac', 'azh', 'wz', 'aez', 'ao', 'waz', 'azd', 'mz', 'taz', 'kaz', 'aj', 'iz', 'azz', 'azm', 'abz', 'vz', 'ap', 'ahz', 'aw', 'uaz', 'azj', 'kz', 'aiz', 'a', 'jaz', 'oz', 'anz', 'ah', 'naz', 'ae', 'ay', 'azr', 'awz', 'zaz', 'ez', 'rz', 'ag', 'azv', 'an', 'aze', 'saz', 'azq', 'oaz', 'au', 'bz', 'uz', 'as', 'azn', 'at', 'azi', 'fz'}\n",
      "ai\n",
      "{'ri', 'afi', 'api', 'vi', 'aif', 'li', 'vai', 'oi', 'ami', 'aoi', 'aji', 'ui', 'al', 'aiv', 'ak', 'aa', 'oai', 'gai', 'ni', 'uai', 'eai', 'aki', 'di', 'aei', 'wi', 'ab', 'iai', 'ad', 'pai', 'am', 'aib', 'jai', 'aig', 'qai', 'aci', 'air', 'aip', 'tai', 'wai', 'i', 'aid', 'asi', 'xi', 'zi', 'yai', 'aij', 'bi', 'ax', 'ar', 'pi', 'ais', 'aih', 'sai', 'ji', 'mi', 'yi', 'aic', 'ia', 'aq', 'qi', 'bai', 'dai', 'ani', 'agi', 'aie', 'kai', 'av', 'aia', 'ahi', 'hai', 'axi', 'af', 'ail', 'aiq', 'ac', 'ali', 'ao', 'aai', 'nai', 'aj', 'ii', 'zai', 'awi', 'ait', 'ap', 'xai', 'aii', 'aio', 'aw', 'ain', 'si', 'ari', 'aiz', 'adi', 'fi', 'a', 'aix', 'abi', 'ah', 'lai', 'hi', 'aui', 'ti', 'ei', 'ae', 'ay', 'ci', 'rai', 'aiy', 'cai', 'ki', 'gi', 'fai', 'aik', 'ag', 'an', 'az', 'aim', 'mai', 'aiu', 'ayi', 'aiw', 'au', 'as', 'ati', 'at', 'azi', 'aqi', 'avi'}\n",
      "la\n",
      "{'lav', 'na', 'lr', 'lat', 'lja', 'lak', 'za', 'lwa', 'ala', 'lma', 'li', 'ya', 'lay', 'lp', 'lua', 'ca', 'pla', 'al', 'qla', 'ka', 'ea', 'aa', 'lba', 'ela', 'ila', 'sa', 'laq', 'lha', 'ly', 'fla', 'lga', 'lta', 'laj', 'laf', 'lda', 'lw', 'lia', 'lxa', 'ola', 'lf', 'laz', 'vla', 'lan', 'jla', 'laa', 'lag', 'cla', 'l', 'lx', 'dla', 'lna', 'ls', 'lla', 'mla', 'lza', 'ma', 'hla', 'tla', 'lm', 'lo', 'ia', 'qa', 'lka', 'll', 'lab', 'da', 'lg', 'fa', 'kla', 'lam', 'lad', 'lao', 'lah', 'ua', 'ula', 'rla', 'law', 'lz', 'lqa', 'yla', 'lfa', 'lra', 'wla', 'pa', 'xla', 'lal', 'ta', 'ld', 'lc', 'lau', 'lax', 'ha', 'a', 'lt', 'lpa', 'va', 'lb', 'loa', 'lea', 'lca', 'le', 'lj', 'lq', 'lu', 'zla', 'lai', 'lv', 'lya', 'wa', 'ba', 'gla', 'lar', 'lsa', 'lap', 'oa', 'sla', 'bla', 'lk', 'ln', 'ra', 'lac', 'lae', 'las', 'xa', 'lva', 'ga', 'nla', 'ja', 'lh'}\n",
      "xa\n",
      "{'na', 'xra', 'xaa', 'za', 'xaf', 'xap', 'ya', 'xia', 'xt', 'gxa', 'xar', 'xea', 'ca', 'xta', 'xpa', 'xq', 'ka', 'ea', 'xx', 'dxa', 'xfa', 'aa', 'xas', 'xha', 'xak', 'xag', 'xsa', 'sa', 'xr', 'qxa', 'xl', 'xqa', 'xz', 'xad', 'xan', 'rxa', 'xva', 'cxa', 'lxa', 'uxa', 'xi', 'xd', 'xda', 'xal', 'xf', 'sxa', 'ax', 'bxa', 'ixa', 'xy', 'xe', 'oxa', 'xae', 'la', 'xat', 'xaz', 'yxa', 'x', 'ma', 'xwa', 'nxa', 'ia', 'qa', 'wxa', 'xax', 'xza', 'hxa', 'xma', 'da', 'xaq', 'fa', 'xg', 'xca', 'xay', 'xn', 'xba', 'kxa', 'xp', 'ua', 'xga', 'xc', 'mxa', 'xxa', 'xo', 'fxa', 'pa', 'xah', 'xua', 'xaj', 'xla', 'txa', 'jxa', 'xau', 'xna', 'ta', 'xab', 'xs', 'xai', 'vxa', 'xh', 'ha', 'xu', 'xja', 'a', 'va', 'pxa', 'xam', 'wa', 'xaw', 'ba', 'zxa', 'xka', 'oa', 'xv', 'ra', 'xoa', 'xao', 'xb', 'xj', 'axa', 'exa', 'xac', 'xya', 'xm', 'xav', 'ga', 'xk', 'ja', 'xw'}\n",
      "h\n",
      "{'', 'hd', 'hg', 'sh', 'z', 'hn', 'q', 'o', 'uh', 'v', 'hj', 'c', 'n', 'gh', 'hv', 'hz', 'ih', 'y', 'kh', 'p', 'f', 'hm', 'b', 'qh', 'm', 'hy', 'hw', 'hk', 'k', 'he', 'ch', 'g', 'ph', 'rh', 's', 'eh', 'w', 'zh', 'ho', 't', 'jh', 'mh', 'fh', 'xh', 'bh', 'ha', 'th', 'hp', 'a', 'ah', 'd', 'hi', 'i', 'nh', 'wh', 'hc', 'yh', 'r', 'l', 'hf', 'j', 'hr', 'vh', 'e', 'hq', 'hu', 'hh', 'hx', 'ht', 'dh', 'hl', 'hs', 'u', 'oh', 'x', 'hb', 'lh'}\n",
      "au\n",
      "{'ahu', 'aqu', 'aum', 'aut', 'cu', 'zu', 'al', 'azu', 'aru', 'ak', 'auz', 'aa', 'aou', 'oau', 'pu', 'fu', 'ab', 'iu', 'ad', 'auu', 'aup', 'am', 'fau', 'afu', 'auo', 'axu', 'wau', 'agu', 'su', 'nau', 'zau', 'eau', 'ax', 'vu', 'asu', 'wu', 'gau', 'sau', 'ar', 'pau', 'apu', 'vau', 'hu', 'ai', 'aua', 'rau', 'auv', 'ku', 'mau', 'aq', 'alu', 'ru', 'aku', 'yau', 'tau', 'qu', 'amu', 'av', 'aul', 'auf', 'eu', 'ua', 'avu', 'af', 'auc', 'auk', 'uu', 'ac', 'aeu', 'auh', 'ao', 'aux', 'ou', 'xau', 'yu', 'aj', 'aun', 'aub', 'bau', 'ap', 'ju', 'aud', 'aw', 'aug', 'lau', 'hau', 'kau', 'ayu', 'aau', 'xu', 'auq', 'dau', 'acu', 'a', 'tu', 'auw', 'ah', 'qau', 'atu', 'jau', 'adu', 'lu', 'aui', 'anu', 'ae', 'ay', 'aue', 'iau', 'nu', 'aus', 'auy', 'abu', 'aju', 'ag', 'an', 'az', 'mu', 'gu', 'aur', 'uau', 'aiu', 'auj', 'cau', 'u', 'as', 'awu', 'du', 'at', 'bu'}\n",
      "u\n",
      "{'', 'z', 'ru', 'q', 'uj', 'o', 'uh', 'v', 'c', 'n', 'qu', 'cu', 'ur', 'uy', 'y', 'eu', 'p', 'f', 'ua', 'ui', 'zu', 'b', 'uw', 'm', 'uv', 'ut', 'uu', 'ue', 'k', 'ud', 'g', 'ul', 'ou', 's', 'yu', 'uo', 'un', 'w', 'pu', 'fu', 't', 'ju', 'iu', 'ub', 'xu', 'a', 'tu', 'd', 'lu', 'i', 'us', 'su', 'um', 'up', 'uf', 'nu', 'vu', 'ux', 'wu', 'uq', 'r', 'l', 'j', 'ug', 'hu', 'e', 'mu', 'gu', 'uc', 'uk', 'h', 'au', 'uz', 'x', 'du', 'ku', 'bu'}\n",
      "as\n",
      "{'ams', 'als', 'ass', 'aqs', 'gs', 'ns', 'asw', 'ahs', 'rs', 'acs', 'has', 'al', 'yas', 'ak', 'aa', 'xas', 'uas', 'jas', 'ags', 'das', 'oas', 'sa', 'afs', 'es', 'ab', 'zs', 'ash', 'ad', 'asj', 'asm', 'qas', 'am', 'ays', 'zas', 'aos', 'nas', 'asz', 'asg', 'eas', 'asi', 'us', 'cs', 'ax', 'asu', 'ar', 'asc', 'ps', 'ais', 'aws', 'ras', 'ai', 'qs', 'ans', 'ase', 'hs', 'ls', 'ars', 'aes', 'was', 'vas', 'ws', 'ss', 'aq', 'aso', 'bas', 'vs', 'fas', 'ds', 'ats', 'azs', 'av', 'ast', 'asq', 'aks', 'pas', 'aps', 'mas', 'af', 'sas', 'ys', 'avs', 'ask', 'ac', 'ks', 'ias', 'tas', 'asr', 'ao', 's', 'asx', 'aj', 'is', 'ads', 'asy', 'xs', 'axs', 'ap', 'fs', 'asv', 'gas', 'aw', 'asa', 'asl', 'a', 'cas', 'ah', 'asd', 'kas', 'asb', 'ae', 'ay', 'aas', 'js', 'aus', 'os', 'asn', 'ag', 'an', 'az', 'asp', 'ts', 'las', 'ajs', 'asf', 'au', 'abs', 'ms', 'at', 'bs'}\n",
      "ga\n",
      "{'na', 'gka', 'gn', 'gah', 'gs', 'za', 'gaw', 'gax', 'ya', 'gea', 'gxa', 'jga', 'gap', 'ca', 'sga', 'gaf', 'gua', 'gpa', 'gra', 'gc', 'gl', 'ka', 'ea', 'aa', 'goa', 'g', 'gaz', 'gai', 'go', 'fga', 'ega', 'gac', 'gad', 'gna', 'gar', 'gy', 'vga', 'gae', 'sa', 'gp', 'gk', 'gba', 'lga', 'gd', 'gw', 'bga', 'aga', 'gia', 'gq', 'gz', 'uga', 'yga', 'gao', 'dga', 'gau', 'gfa', 'mga', 'gma', 'gya', 'la', 'gha', 'gb', 'gca', 'ma', 'ia', 'qa', 'cga', 'gab', 'gam', 'tga', 'da', 'gg', 'gh', 'gwa', 'fa', 'gaj', 'gga', 'iga', 'gal', 'gza', 'xga', 'ua', 'gqa', 'gf', 'gta', 'qga', 'rga', 'gv', 'pga', 'pa', 'oga', 'gag', 'gay', 'ta', 'ge', 'gav', 'gva', 'gas', 'kga', 'gak', 'ha', 'gan', 'zga', 'a', 'va', 'gja', 'gda', 'gm', 'wa', 'gaa', 'gx', 'nga', 'gat', 'ba', 'gla', 'wga', 'oa', 'gt', 'gi', 'ra', 'hga', 'ag', 'gr', 'gu', 'gsa', 'xa', 'gj', 'ja', 'gaq'}\n",
      "x\n",
      "{'', 'z', 'q', 'o', 'v', 'c', 'n', 'cx', 'jx', 'xg', 'xn', 'xt', 'y', 'p', 'f', 'xp', 'xc', 'b', 'yx', 'm', 'zx', 'xo', 'xq', 'xx', 'mx', 'k', 'g', 'ex', 'ox', 's', 'qx', 'px', 'w', 'bx', 'xs', 'xr', 'xl', 't', 'xz', 'xh', 'ix', 'xu', 'a', 'd', 'i', 'sx', 'xi', 'gx', 'xd', 'xf', 'ax', 'dx', 'xy', 'ux', 'tx', 'r', 'xv', 'l', 'xe', 'j', 'e', 'lx', 'xb', 'xj', 'vx', 'kx', 'hx', 'xa', 'h', 'nx', 'u', 'wx', 'fx', 'xm', 'rx', 'xk', 'xw'}\n",
      "ma\n",
      "{'mar', 'na', 'mza', 'mqa', 'nma', 'mm', 'mam', 'mda', 'mt', 'za', 'mc', 'lma', 'md', 'ya', 'mae', 'max', 'ca', 'mag', 'm', 'uma', 'ka', 'ea', 'mx', 'moa', 'aa', 'mw', 'mav', 'mha', 'sa', 'mj', 'may', 'mpa', 'cma', 'msa', 'me', 'am', 'mf', 'mac', 'kma', 'rma', 'bma', 'mat', 'mak', 'tma', 'pma', 'mv', 'mq', 'mga', 'mua', 'ml', 'gma', 'la', 'mwa', 'mla', 'mia', 'maw', 'mi', 'man', 'mau', 'ia', 'qa', 'jma', 'xma', 'maz', 'da', 'mva', 'fa', 'dma', 'mo', 'sma', 'ima', 'maj', 'ua', 'vma', 'mas', 'mxa', 'pa', 'mea', 'mz', 'mg', 'ama', 'maf', 'ta', 'mad', 'mal', 'wma', 'mh', 'mr', 'mka', 'ha', 'zma', 'mp', 'a', 'va', 'mba', 'mah', 'maq', 'mfa', 'wa', 'mb', 'mna', 'map', 'ba', 'oma', 'mja', 'mra', 'oa', 'qma', 'ra', 'mca', 'mab', 'mn', 'mta', 'mao', 'mma', 'yma', 'mu', 'mya', 'my', 'xa', 'mai', 'mk', 'fma', 'ms', 'maa', 'ga', 'hma', 'ja', 'ema'}\n",
      "at\n",
      "{'ot', 'lat', 'atc', 'atk', 'art', 'aut', 'atd', 'mt', 'apt', 'xt', 'zt', 'yt', 'nat', 'fat', 'uat', 'al', 'amt', 'hat', 'aft', 'ak', 'aot', 'aa', 'ajt', 'atf', 'avt', 'ft', 'atb', 'atv', 'atg', 'ab', 't', 'yat', 'att', 'atx', 'it', 'ad', 'bat', 'atn', 'am', 'rt', 'ct', 'kt', 'wt', 'agt', 'atp', 'mat', 'alt', 'atw', 'awt', 'ax', 'dat', 'atr', 'aht', 'oat', 'ar', 'et', 'adt', 'tat', 'ai', 'atj', 'tt', 'xat', 'ht', 'dt', 'nt', 'akt', 'azt', 'atz', 'aq', 'vt', 'kat', 'ant', 'ats', 'av', 'ast', 'ate', 'atq', 'iat', 'af', 'sat', 'ut', 'ac', 'qat', 'atm', 'ao', 'bt', 'aj', 'vat', 'cat', 'ta', 'ath', 'aty', 'ait', 'ata', 'axt', 'ap', 'aqt', 'rat', 'aw', 'pt', 'wat', 'jat', 'a', 'lt', 'ah', 'st', 'atu', 'qt', 'ato', 'eat', 'pat', 'abt', 'ae', 'ay', 'gat', 'gt', 'ag', 'act', 'an', 'jt', 'az', 'zat', 'ayt', 'atl', 'au', 'as', 'aet', 'ati', 'aat'}\n",
      "ja\n",
      "{'na', 'lja', 'cja', 'za', 'jn', 'tja', 'jx', 'oja', 'ya', 'jar', 'jca', 'nja', 'jj', 'uja', 'jga', 'ca', 'jac', 'jc', 'jr', 'jm', 'jaq', 'jk', 'aja', 'ka', 'ea', 'jam', 'je', 'jay', 'aa', 'jaf', 'jw', 'jy', 'jas', 'jda', 'jag', 'ija', 'jpa', 'sa', 'jfa', 'jah', 'jh', 'dja', 'jp', 'jza', 'jai', 'jqa', 'jz', 'kja', 'wja', 'sja', 'jha', 'jaj', 'jak', 'jla', 'jap', 'joa', 'jg', 'jia', 'hja', 'la', 'jq', 'ji', 'eja', 'ma', 'jae', 'ia', 'qa', 'jo', 'jsa', 'jma', 'bja', 'da', 'jaa', 'fa', 'jab', 'jka', 'ua', 'jb', 'yja', 'jv', 'jra', 'jba', 'pa', 'jwa', 'jya', 'jax', 'jxa', 'vja', 'jva', 'aj', 'jaw', 'ta', 'ju', 'fja', 'jad', 'jta', 'ha', 'xja', 'jat', 'a', 'jua', 'jaz', 'va', 'zja', 'rja', 'gja', 'jau', 'jal', 'jav', 'jd', 'wa', 'ba', 'jja', 'js', 'mja', 'oa', 'ra', 'jl', 'pja', 'jan', 'j', 'qja', 'jt', 'jf', 'xa', 'jna', 'ga', 'jea', 'jao'}\n"
     ]
    }
   ],
   "source": [
    "for w in edit_one:\n",
    "    if w:\n",
    "        print(w)\n",
    "        edit_two = edit_one_letter(w, True)\n",
    "        print(edit_two)\n",
    "    else:\n",
    "        print(\"Not w found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b9c4a8a72cf4b1f8d918f50ea71471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
    "# UNQ_C9 GRADED FUNCTION: edit_two_letters\n",
    "def edit_two_letters(word, allow_switches=True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the input string/word\n",
    "    Output:\n",
    "        edit_two_set: a set of strings with all possible two edits\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    edit_one = edit_one_letter(word, allow_switches)\n",
    "    print(edit_one)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # return this as a set instead of a list\n",
    "    return (e2 for e1 in edit_one for e2 in edit_one_letter(e1, allow_switches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ac66cc227d6849679926c348b4c9ff06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'', 'na', 'ia', 'z', 'qa', 'aq', 'q', 'o', 'v', 'c', 'n', 'da', 'za', 'fa', 'av', 'ya', 'y', 'ca', 'p', 'f', 'ua', 'b', 'af', 'm', 'al', 'ka', 'ea', 'ak', 'ac', 'k', 'aa', 'pa', 'g', 'ao', 's', 'aj', 'w', 'ta', 'sa', 'ap', 'ab', 't', 'aw', 'ad', 'am', 'ha', 'va', 'ah', 'd', 'i', 'wa', 'ae', 'ay', 'ba', 'ax', 'oa', 'r', 'ar', 'l', 'ra', 'j', 'ag', 'an', 'e', 'az', 'ai', 'la', 'xa', 'h', 'au', 'u', 'as', 'ga', 'x', 'ma', 'at', 'ja'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-6ef925794a11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtmp_edit_two_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medit_two_letters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtmp_edit_two_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_edit_two_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"First 10 strings {tmp_edit_two_l[:10]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Last 10 strings {tmp_edit_two_l[-10:]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-4fd7605a8bd1>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# return this as a set instead of a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0me2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medit_one\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medit_one_letter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_switches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-ea389d1aba59>\u001b[0m in \u001b[0;36medit_one_letter\u001b[0;34m(word, allow_switches)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_switches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0medit_one_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswitch_letter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0medit_one_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace_letter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0medit_one_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsert_letter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-5312be209528>\u001b[0m in \u001b[0;36mreplace_letter\u001b[0;34m(word, verbose)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mreplace_set\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_l\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mR\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mletters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mreplace_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mreplace_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "tmp_edit_two_set = edit_two_letters(\"a\")\n",
    "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
    "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
    "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
    "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n",
    "print(f\"The data type of the returned object should be a set {type(tmp_edit_two_set)}\")\n",
    "print(\n",
    "    f\"Number of strings that are 2 edit distances from 'at' is {len(edit_two_letters('at'))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24b3151c5443aca10a797b84e318b8",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "\n",
    "```CPP\n",
    "Number of strings with edit distance of two: 2654\n",
    "First 10 strings ['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag']\n",
    "Last 10 strings ['zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n",
    "The data type of the returned object should be a set <class 'set'>\n",
    "Number of strings that are 2 edit distances from 'at' is 7154\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78d30bef722d422e9b8ce9ad9120e77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong output type.\n",
      "\tExpected: 7130.\n",
      "\tGot: 1.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/work/w1_unittest.py\u001b[0m in \u001b[0;36mtest_edit_two_letters\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m   1622\u001b[0m             assert sorted(list(result))[:10] == sorted(\n\u001b[0;32m-> 1623\u001b[0;31m                 \u001b[0mtest_case\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"expected\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"expected_head\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m             )\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-3b36c6903fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test your function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw1_unittest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_edit_two_letters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medit_two_letters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/w1_unittest.py\u001b[0m in \u001b[0;36mtest_edit_two_letters\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                     \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_case\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                     \u001b[0;34m\"expected\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_case\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"expected\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"expected_head\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                     \u001b[0;34m\"got\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m                 }\n\u001b[1;32m   1633\u001b[0m             )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "w1_unittest.test_edit_two_letters(edit_two_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4fcf6e28df446b8d68a4fd0ab5311a",
   "metadata": {},
   "source": [
    "<a name='3-3'></a>\n",
    "### 3.3 - Suggest Spelling Suggestions\n",
    "\n",
    "Now you will use your `edit_two_letters` function to get a set of all the possible 2 edits on your word. You will then use those strings to get the most probable word you meant to type a.k.a your typing suggestion.\n",
    "\n",
    "<a name='ex-10'></a>\n",
    "### Exercise 10 - get_corrections\n",
    "**Instructions**: Implement `get_corrections`, which returns a list of zero to n possible suggestion tuples of the form (word, probability_of_word). \n",
    "\n",
    "**Step 1:** Generate suggestions for a supplied word: You'll use the edit functions you have developed. The 'suggestion algorithm' should follow this logic: \n",
    "* If the word is in the vocabulary, suggest the word. \n",
    "* Otherwise, if there are suggestions from `edit_one_letter` that are in the vocabulary, use those. \n",
    "* Otherwise, if there are suggestions from `edit_two_letters` that are in the vocabulary, use those. \n",
    "* Otherwise, suggest the input word.*  \n",
    "* The idea is that words generated from fewer edits are more likely than words with more edits.\n",
    "\n",
    "\n",
    "Note: \n",
    "- Edits of two letters may 'restore' strings to either zero or one edit. This algorithm accounts for this by preferentially selecting lower distance edits first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b9e19d572d4a358a6466b5ae101f4b",
   "metadata": {},
   "source": [
    "#### Short circuit\n",
    "In Python, logical operations such as `and` and `or` have two useful properties. They can operate on lists and they have ['short-circuit' behavior](https://docs.python.org/3/library/stdtypes.html). Try these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16fcee922c7341adb30443c16ae77ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['a', 'b']\n",
      "['Most', 'Likely']\n",
      "['least', 'of', 'all']\n"
     ]
    }
   ],
   "source": [
    "# example of logical operation on lists or sets\n",
    "print([] and [\"a\", \"b\"])\n",
    "print([] or [\"a\", \"b\"])\n",
    "# example of Short circuit behavior\n",
    "val1 = (\n",
    "    [\"Most\", \"Likely\"] or [\"Less\", \"so\"] or [\"least\", \"of\", \"all\"]\n",
    ")  # selects first, does not evalute remainder\n",
    "print(val1)\n",
    "val2 = (\n",
    "    [] or [] or [\"least\", \"of\", \"all\"]\n",
    ")  # continues evaluation until there is a non-empty list\n",
    "print(val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a366c65ec8f43a7b6c6a1f99eedcdc7",
   "metadata": {},
   "source": [
    "The logical `or` could be used to implement the suggestion algorithm very compactly. Alternately, if/elif/else constructs could be used.\n",
    " \n",
    "**Step 2**: Create a 'best_words' dictionary where the 'key' is a suggestion and the 'value' is the probability of that word in your vocabulary. If the word is not in the vocabulary, assign it a probability of 0.\n",
    "\n",
    "**Step 3**: Select the n best suggestions. There may be fewer than n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285292c481204fb9827713150300700d",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>edit_one_letter and edit_two_letters return *python sets*. </li>\n",
    "    <li> Sets have a handy <a href=\"https://docs.python.org/2/library/sets.html\" > set.intersection </a> feature</li>\n",
    "    <li>To find the keys that have the highest values in a dictionary, you can use the Counter dictionary to create a Counter object from a regular dictionary.  Then you can use Counter.most_common(n) to get the n most common keys.\n",
    "    </li>\n",
    "    <li>To find the intersection of two sets, you can use set.intersection or the & operator.</li>\n",
    "    <li>If you are not as familiar with short circuit syntax (as shown above), feel free to use if else statements instead.</li>\n",
    "    <li>To use an if statement to check of a set is empty, use 'if not x:' syntax </li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "70a442e5a22549c3aeed8bbde344c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
    "# UNQ_C10 GRADED FUNCTION: get_corrections\n",
    "def get_corrections(word, probs, vocab, n=2, verbose=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: a user entered string to check for suggestions\n",
    "        probs: a dictionary that maps each word to its probability in the corpus\n",
    "        vocab: a set containing all the vocabulary\n",
    "        n: number of possible word corrections you want returned in the dictionary\n",
    "    Output:\n",
    "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
    "    \"\"\"\n",
    "    suggestions = []\n",
    "    n_best = []\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: create suggestions as described above\n",
    "    suggestions = set()\n",
    "    # generate suggestions\n",
    "    suggestions = suggestions.union(edit_one_letter(word))\n",
    "    suggestions = suggestions.union(delete_letter(word))\n",
    "    suggestions = suggestions.union(replace_letter(word))\n",
    "    suggestions = suggestions.union(insert_letter(word))\n",
    "    suggestions = suggestions.intersection(vocab)\n",
    "\n",
    "    # Step 2: determine probability of suggestions\n",
    "    probs_suggestions = {s: probs.get(s, 0) for s in suggestions}\n",
    "\n",
    "    # Step 3: Get all your best words and return the most probable top n_suggested words as n_best\n",
    "\n",
    "    n_best = sorted(probs_suggestions.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    if verbose:\n",
    "        print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
    "\n",
    "    return n_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d8f3ad71ef4e4fb28db20bbdf1072eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered word =  dys \n",
      "suggestions =  {'dye', 'days'}\n",
      "word 0: days, probability 0.000410\n",
      "word 1: dye, probability 0.000019\n",
      "data type of corrections <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation - feel free to try other words in my word\n",
    "my_word = \"dys\"\n",
    "tmp_corrections = get_corrections(\n",
    "    my_word, probs, vocab, 2, verbose=True\n",
    ")  # keep verbose=True\n",
    "for i, word_prob in enumerate(tmp_corrections):\n",
    "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n",
    "\n",
    "# CODE REVIEW COMMENT: using \"tmp_corrections\" insteads of \"cors\". \"cors\" is not defined\n",
    "print(f\"data type of corrections {type(tmp_corrections)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e76ba5fa5224758ab53e4bf3add65ea",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "- Note: This expected output is for `my_word = 'dys'`. Also, keep `verbose=True`\n",
    "```CPP\n",
    "entered word =  dys \n",
    "suggestions =  {'days', 'dye'}\n",
    "word 0: days, probability 0.000410\n",
    "word 1: dye, probability 0.000019\n",
    "data type of corrections <class 'list'>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b83c526139964f048bfc0ec11c5c4ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "w1_unittest.test_get_corrections(get_corrections, probs, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ea7564f88472abbb323838811e9bb",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Minimum Edit Distance\n",
    "\n",
    "Now that you have implemented your auto-correct, how do you evaluate the similarity between two strings? For example: 'waht' and 'what'\n",
    "\n",
    "Also how do you efficiently find the shortest path to go from the word, 'waht' to the word 'what'?\n",
    "\n",
    "You will implement a dynamic programming system that will tell you the minimum number of edits required to convert a string into another string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb6be3a914446a944d34ac5dc2a2dc",
   "metadata": {},
   "source": [
    "<a name='4-1'></a>\n",
    "### 4.1 - Dynamic Programming\n",
    "\n",
    "Dynamic Programming breaks a problem down into subproblems which can be combined to form the final solution. Here, given a string source[0..i] and a string target[0..j], we will compute all the combinations of substrings[i, j] and calculate their edit distance. To do this efficiently, we will use a table to maintain the previously computed substrings and use those to calculate larger substrings.\n",
    "\n",
    "You have to create a matrix and update each element in the matrix as follows:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75c0d1da0e4801a8ace6d8dfdccdd5",
   "metadata": {},
   "source": [
    "$$\\text{Initialization}$$\n",
    "\n",
    "\\begin{align}\n",
    "D[0,0] &= 0 \\\\\n",
    "D[i,0] &= D[i-1,0] + del\\_cost(source[i]) \\tag{4}\\\\\n",
    "D[0,j] &= D[0,j-1] + ins\\_cost(target[j]) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471949106b36446989bda27c11c07ffe",
   "metadata": {},
   "source": [
    "\n",
    "$$\\text{Per Cell Operations}$$\n",
    "\\begin{align}\n",
    " \\\\\n",
    "D[i,j] =min\n",
    "\\begin{cases}\n",
    "D[i-1,j] + del\\_cost\\\\\n",
    "D[i,j-1] + ins\\_cost\\\\\n",
    "D[i-1,j-1] + \\left\\{\\begin{matrix}\n",
    "rep\\_cost; & if src[i]\\neq tar[j]\\\\\n",
    "0 ; & if src[i]=tar[j]\n",
    "\\end{matrix}\\right.\n",
    "\\end{cases}\n",
    "\\tag{5}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec600946ecd4845ad19f64192a831ba",
   "metadata": {},
   "source": [
    "So converting the source word **play** to the target word **stay**, using an input cost of one, a delete cost of 1, and replace cost of 2 would give you the following table:\n",
    "<table style=\"width:20%\">\n",
    "\n",
    "  <tr>\n",
    "    <td> <b> </b>  </td>\n",
    "    <td> <b># </b>  </td>\n",
    "    <td> <b>s </b>  </td>\n",
    "    <td> <b>t </b> </td> \n",
    "    <td> <b>a </b> </td> \n",
    "    <td> <b>y </b> </td> \n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td> <b>  #  </b></td>\n",
    "    <td> 0</td> \n",
    "    <td> 1</td> \n",
    "    <td> 2</td> \n",
    "    <td> 3</td> \n",
    "    <td> 4</td> \n",
    " \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> <b>  p  </b></td>\n",
    "    <td> 1</td> \n",
    " <td> 2</td> \n",
    "    <td> 3</td> \n",
    "    <td> 4</td> \n",
    "   <td> 5</td>\n",
    "  </tr>\n",
    "   \n",
    "  <tr>\n",
    "    <td> <b> l </b></td>\n",
    "    <td>2</td> \n",
    "    <td>3</td> \n",
    "    <td>4</td> \n",
    "    <td>5</td> \n",
    "    <td>6</td>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td> <b> a </b></td>\n",
    "    <td>3</td> \n",
    "     <td>4</td> \n",
    "     <td>5</td> \n",
    "     <td>4</td>\n",
    "     <td>5</td> \n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td> <b> y </b></td>\n",
    "    <td>4</td> \n",
    "      <td>5</td> \n",
    "     <td>6</td> \n",
    "     <td>5</td>\n",
    "     <td>4</td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d4859d4874362a1b7a6ee216877f0",
   "metadata": {},
   "source": [
    "The operations used in this algorithm are 'insert', 'delete', and 'replace'. These correspond to the functions that you defined earlier: insert_letter(), delete_letter() and replace_letter(). switch_letter() is not used here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d02ab4392c4890bbe111e09569d325",
   "metadata": {},
   "source": [
    "The diagram below describes how to initialize the table. Each entry in D[i,j] represents the minimum cost of converting string source[0:i] to string target[0:j]. The first column is initialized to represent the cumulative cost of deleting the source characters to convert string \"EER\" to \"\". The first row is initialized to represent the cumulative cost of inserting the target characters to convert from \"\" to \"NEAR\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d2bca8277b4eb596a056b79c7e9bcb",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/EditDistInit4.PNG' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:1000px;height:400px;\"/> Figure 6 Initializing Distance Matrix</div>     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbcff25c69944daba8066f28941e138",
   "metadata": {},
   "source": [
    "Filling in the remainder of the table utilizes the 'Per Cell Operations' in the equation (5) above. Note, the diagram below includes in the table some of the 3 sub-calculations shown in light grey. Only 'min' of those operations is stored in the table in the `min_edit_distance()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f549461620ea4eed9a2f326eb12847bb",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/EditDistFill2.PNG' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:800px;height:400px;\"/> Figure 7 Filling Distance Matrix</div>     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716298bd59234545a22eae9583c852d3",
   "metadata": {},
   "source": [
    "Note that the formula for $D[i,j]$ shown in the image is equivalent to:\n",
    "\n",
    "\\begin{align}\n",
    " \\\\\n",
    "D[i,j] =min\n",
    "\\begin{cases}\n",
    "D[i-1,j] + del\\_cost\\\\\n",
    "D[i,j-1] + ins\\_cost\\\\\n",
    "D[i-1,j-1] + \\left\\{\\begin{matrix}\n",
    "rep\\_cost; & if src[i]\\neq tar[j]\\\\\n",
    "0 ; & if src[i]=tar[j]\n",
    "\\end{matrix}\\right.\n",
    "\\end{cases}\n",
    "\\tag{5}\n",
    "\\end{align}\n",
    "\n",
    "The variable `sub_cost` (for substitution cost) is the same as `rep_cost`; replacement cost.  We will stick with the term \"replace\" whenever possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b92e194e2413086eba32c146deebf",
   "metadata": {},
   "source": [
    "Below are some examples of cells where replacement is used. This also shows the minimum path from the lower right final position where \"EER\" has been replaced by \"NEAR\" back to the start. This provides a starting point for the optional 'backtrace' algorithm below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb17d636944b8f92b9cfeabba6cab2",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/EditDistExample1.PNG' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:1200px;height:400px;\"/> Figure 8 Examples Distance Matrix</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db356ca990461c9e1486d4ed6e54cb",
   "metadata": {},
   "source": [
    "<a name='ex-11'></a>\n",
    "### Exercise 11 - min_edit_distance\n",
    "\n",
    "Again, the word \"substitution\" appears in the figure, but think of this as \"replacement\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3eff90819d466591de76416c35ecaf",
   "metadata": {},
   "source": [
    "**Instructions**: Implement the function below to get the minimum amount of edits required given a source string and a target string. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ee281e7494d5881c86a91de832186",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>The range(start, stop, step) function excludes 'stop' from its output</li>\n",
    "    <li><a href=\"\" > words </a> </li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "376688ed411e4ed68946298798fb22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C11 GRADED FUNCTION: min_edit_distance\n",
    "def min_edit_distance(source, target, ins_cost=1, del_cost=1, rep_cost=2):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        source: a string corresponding to the string you are starting with\n",
    "        target: a string corresponding to the string you want to end with\n",
    "        ins_cost: an integer setting the insert cost\n",
    "        del_cost: an integer setting the delete cost\n",
    "        rep_cost: an integer setting the replace cost\n",
    "    Output:\n",
    "        D: a matrix of len(source)+1 by len(target)+1 containing minimum edit distances\n",
    "        med: the minimum edit distance (med) required to convert the source string to the target\n",
    "    \"\"\"\n",
    "    # use deletion and insert cost as  1\n",
    "    m = len(source)\n",
    "    n = len(target)\n",
    "    # initialize cost matrix with zeros and dimensions (m+1,n+1)\n",
    "    D = np.zeros((m + 1, n + 1), dtype=int)\n",
    "\n",
    "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "\n",
    "    # Fill in column 0, from row 1 to row m, both inclusive\n",
    "    for row in range(1, m + 1):  # Replace None with the proper range\n",
    "        D[row, 0] = D[row - 1, 0] + del_cost\n",
    "\n",
    "    # Fill in row 0, for all columns from 1 to n, both inclusive\n",
    "    for col in range(1, n + 1):  # Replace None with the proper range\n",
    "        D[0, col] = D[0, col - 1] + ins_cost\n",
    "\n",
    "    # Loop through row 1 to row m, both inclusive\n",
    "    for row in range(1, m + 1):\n",
    "\n",
    "        # Loop through column 1 to column n, both inclusive\n",
    "        for col in range(1, n + 1):\n",
    "\n",
    "            # Intialize r_cost to the 'replace' cost that is passed into this function\n",
    "            r_cost = rep_cost\n",
    "\n",
    "            # Check to see if source character at the previous row\n",
    "            # matches the target character at the previous column,\n",
    "            if (\n",
    "                source[row - 1] == target[col - 1]\n",
    "            ):  # Replace None with a proper comparison\n",
    "                # Update the replacement cost to 0 if source and target are the same\n",
    "                r_cost = 0\n",
    "\n",
    "            # Update the cost at row, col based on previous entries in the cost matrix\n",
    "            # Refer to the equation calculate for D[i,j] (the minimum of three calculated costs)\n",
    "            D[row, col] = min(\n",
    "                D[row - 1, col - 1] + r_cost,\n",
    "                D[row - 1, col] + del_cost,\n",
    "                D[row, col - 1] + ins_cost,\n",
    "            )\n",
    "\n",
    "    # Set the minimum edit distance with the cost found at row m, column n\n",
    "    med = D[m, n]\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return D, med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9252b40adaf64597a9bbdc6b7e320347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum edits:  4 \n",
      "\n",
      "   #  s  t  a  y\n",
      "#  0  1  2  3  4\n",
      "p  1  2  3  4  5\n",
      "l  2  3  4  5  6\n",
      "a  3  4  5  4  5\n",
      "y  4  5  6  5  4\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "# testing your implementation\n",
    "source = \"play\"\n",
    "target = \"stay\"\n",
    "matrix, min_edits = min_edit_distance(source, target)\n",
    "print(\"minimum edits: \", min_edits, \"\\n\")\n",
    "idx = list(\"#\" + source)\n",
    "cols = list(\"#\" + target)\n",
    "df = pd.DataFrame(matrix, index=idx, columns=cols)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f84202603804c8197ad3341510ac62d",
   "metadata": {},
   "source": [
    "**Expected Results:**  \n",
    "\n",
    "```CPP\n",
    "minimum edits:  4\n",
    "    \n",
    "   #  s  t  a  y\n",
    "#  0  1  2  3  4\n",
    "p  1  2  3  4  5\n",
    "l  2  3  4  5  6\n",
    "a  3  4  5  4  5\n",
    "y  4  5  6  5  4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c6a8fd7fc9274ff5858d3ae051f1f564",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum edits:  3 \n",
      "\n",
      "   #  n  e  a  r\n",
      "#  0  1  2  3  4\n",
      "e  1  2  1  2  3\n",
      "e  2  3  2  3  4\n",
      "r  3  4  3  4  3\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "# testing your implementation\n",
    "source = \"eer\"\n",
    "target = \"near\"\n",
    "matrix, min_edits = min_edit_distance(source, target)\n",
    "print(\"minimum edits: \", min_edits, \"\\n\")\n",
    "idx = list(source)\n",
    "idx.insert(0, \"#\")\n",
    "cols = list(target)\n",
    "cols.insert(0, \"#\")\n",
    "df = pd.DataFrame(matrix, index=idx, columns=cols)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293a458cd854b6dbf0848da5c69f09a",
   "metadata": {},
   "source": [
    "**Expected Results**  \n",
    "```CPP\n",
    "minimum edits:  3 \n",
    "\n",
    "   #  n  e  a  r\n",
    "#  0  1  2  3  4\n",
    "e  1  2  1  2  3\n",
    "e  2  3  2  3  4\n",
    "r  3  4  3  4  3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a97e765aa57f438e869be2b8642a3a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "w1_unittest.test_min_edit_distance(min_edit_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09375e10c234586bfe3a4ef035f3553",
   "metadata": {},
   "source": [
    "We can now test several of our routines at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "27abfcbceac042beae565679d4b0d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"eer\"\n",
    "targets = edit_one_letter(\n",
    "    source, allow_switches=False\n",
    ")  # disable switches since min_edit_distance does not include them\n",
    "for t in targets:\n",
    "    _, min_edits = min_edit_distance(\n",
    "        source, t, 1, 1, 1\n",
    "    )  # set ins, del, sub costs all to one\n",
    "    if min_edits != 1:\n",
    "        print(source, t, min_edits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a52925388c4f2c90a0671e1201f318",
   "metadata": {},
   "source": [
    "**Expected Results**  \n",
    "```CPP\n",
    "(empty)\n",
    "```\n",
    "\n",
    "The 'replace()' routine utilizes all letters a-z one of which returns the original word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e173022637e4f3a93e48e174a76d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"eer\"\n",
    "targets = edit_two_letters(\n",
    "    source, allow_switches=False\n",
    ")  # disable switches since min_edit_distance does not include them\n",
    "for t in targets:\n",
    "    _, min_edits = min_edit_distance(\n",
    "        source, t, 1, 1, 1\n",
    "    )  # set ins, del, sub costs all to one\n",
    "    if min_edits != 2 and min_edits != 1:\n",
    "        print(source, t, min_edits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a5e65d59f48179b72a4526cdd66e9",
   "metadata": {},
   "source": [
    "**Expected Results**  \n",
    "```CPP\n",
    "eer eer 0\n",
    "```\n",
    "\n",
    "We have to allow single edits here because some two_edits will restore a single edit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8520c81c71f94ff3a6c038fd677488ae",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Make sure you submit your assignment before you modify anything below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b88e3446c3419fa7cb6cfa901ae5cf",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Backtrace (Optional)\n",
    "\n",
    "\n",
    "Once you have computed your matrix using minimum edit distance, how would find the shortest path from the top left corner to the bottom right corner? \n",
    "\n",
    "Note that you could use backtrace algorithm.  Try to find the shortest path given the matrix that your `min_edit_distance` function returned.\n",
    "\n",
    "You can use these [lecture slides on minimum edit distance](https://web.stanford.edu/class/cs124/lec/med.pdf) by Dan Jurafsky to learn about the algorithm for backtrace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426aae77639425691cf43cd8296cb1d",
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "# Experiment with back trace - insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f571f178b3b492089c46abfbd376ff0",
   "metadata": {},
   "source": [
    "#### References\n",
    "- Dan Jurafsky - Speech and Language Processing - Textbook\n",
    "- This auto-correct explanation was first done by Peter Norvig in 2007 "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
