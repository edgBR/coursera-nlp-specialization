

## Coursera NLP specialization Learning Notes

This repository contains personal notes about the NLP (Natural Language Processing) Specialization of [DeepLearning.AI](https://www.deeplearning.ai/).

The purpose of the course is to lay the foundations to understand seq2seq models and attention models. The course is divided in 4+1 main chapters.

1.  The [first chapter](docs/natural_language_processing_with_classification_and_vector_spaces) uses [Logistic Regression](docs/natural_language_processing_with_classification_and_vector_spaces/lecture_1.md) and [Bayes classifiers](docs/natural_language_processing_with_classification_and_vector_spaces/lecture_2.md) to perform sentiment classification. This course also deep dives about the different [word representation techniques](docs/natural_language_processing_with_classification_and_vector_spaces/lecture_3.md). Finally a basic machine learning translation system is built frond the ground and the first search method (sensitive hashing) is introduced.

2.  The second chapter focus about probability theory in NLP models. We explore the different algorithms that can be used to predict the next word in a sentence as well as how to compare these predictions against others.

3.  The third chapter is centered around seq2seq models.

4.  The final course teaches the attention models and the attention mechanism. This course also gives us the background to implement the most common NLP use cases like text summarization, machine translation, chatbots and question and answering.

5.  Chapter 5 is a practical chapter where we use Azure AI services to train, efficient fine-tuning, deploy NLP models into the cloud. Besides we explore fundational models, prompt-engineering, retrieval augment generation (RAG)
